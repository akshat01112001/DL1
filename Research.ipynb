{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAbC/9cSREf/QLc9YWJqW8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akshat01112001/DL1/blob/main/Research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCxFtvqBAOEh",
        "outputId": "fb2fa6af-1ab2-45ac-9a68-da992d8007c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  cuda-11-8 cuda-cccl-11-8 cuda-command-line-tools-11-8 cuda-compiler-11-8\n",
            "  cuda-cudart-11-8 cuda-cudart-dev-11-8 cuda-cuobjdump-11-8 cuda-cupti-11-8\n",
            "  cuda-cupti-dev-11-8 cuda-cuxxfilt-11-8 cuda-demo-suite-11-8\n",
            "  cuda-documentation-11-8 cuda-driver-dev-11-8 cuda-gdb-11-8\n",
            "  cuda-libraries-11-8 cuda-libraries-dev-11-8 cuda-memcheck-11-8\n",
            "  cuda-nsight-11-8 cuda-nsight-compute-11-8 cuda-nsight-systems-11-8\n",
            "  cuda-nvcc-11-8 cuda-nvdisasm-11-8 cuda-nvml-dev-11-8 cuda-nvprof-11-8\n",
            "  cuda-nvprune-11-8 cuda-nvrtc-11-8 cuda-nvrtc-dev-11-8 cuda-nvtx-11-8\n",
            "  cuda-nvvp-11-8 cuda-profiler-api-11-8 cuda-runtime-11-8 cuda-sanitizer-11-8\n",
            "  cuda-toolkit-11-8 cuda-toolkit-11-8-config-common cuda-tools-11-8\n",
            "  cuda-visual-tools-11-8 gds-tools-11-8 libcublas-11-8 libcublas-dev-11-8\n",
            "  libcufft-11-8 libcufft-dev-11-8 libcufile-11-8 libcufile-dev-11-8\n",
            "  libcurand-11-8 libcurand-dev-11-8 libcusolver-11-8 libcusolver-dev-11-8\n",
            "  libcusparse-11-8 libcusparse-dev-11-8 libnpp-11-8 libnpp-dev-11-8\n",
            "  libnvjpeg-11-8 libnvjpeg-dev-11-8 libxcb-xinput0 nsight-compute-2022.3.0\n",
            "  nsight-systems-2022.4.2\n",
            "The following NEW packages will be installed:\n",
            "  cuda cuda-11-8 cuda-cccl-11-8 cuda-command-line-tools-11-8\n",
            "  cuda-compiler-11-8 cuda-cudart-11-8 cuda-cudart-dev-11-8 cuda-cuobjdump-11-8\n",
            "  cuda-cupti-11-8 cuda-cupti-dev-11-8 cuda-cuxxfilt-11-8 cuda-demo-suite-11-8\n",
            "  cuda-documentation-11-8 cuda-driver-dev-11-8 cuda-gdb-11-8\n",
            "  cuda-libraries-11-8 cuda-libraries-dev-11-8 cuda-memcheck-11-8\n",
            "  cuda-nsight-11-8 cuda-nsight-compute-11-8 cuda-nsight-systems-11-8\n",
            "  cuda-nvcc-11-8 cuda-nvdisasm-11-8 cuda-nvml-dev-11-8 cuda-nvprof-11-8\n",
            "  cuda-nvprune-11-8 cuda-nvrtc-11-8 cuda-nvrtc-dev-11-8 cuda-nvtx-11-8\n",
            "  cuda-nvvp-11-8 cuda-profiler-api-11-8 cuda-runtime-11-8 cuda-sanitizer-11-8\n",
            "  cuda-toolkit-11-8 cuda-toolkit-11-8-config-common cuda-tools-11-8\n",
            "  cuda-visual-tools-11-8 gds-tools-11-8 libcublas-11-8 libcublas-dev-11-8\n",
            "  libcufft-11-8 libcufft-dev-11-8 libcufile-11-8 libcufile-dev-11-8\n",
            "  libcurand-11-8 libcurand-dev-11-8 libcusolver-11-8 libcusolver-dev-11-8\n",
            "  libcusparse-11-8 libcusparse-dev-11-8 libnpp-11-8 libnpp-dev-11-8\n",
            "  libnvjpeg-11-8 libnvjpeg-dev-11-8 libxcb-xinput0 nsight-compute-2022.3.0\n",
            "  nsight-systems-2022.4.2\n",
            "0 upgraded, 57 newly installed, 0 to remove and 5 not upgraded.\n",
            "Need to get 2,713 MB of archives.\n",
            "After this operation, 6,661 MB of additional disk space will be used.\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-8-config-common 11.8.89-1 [16.3 kB]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-11-8 11.8.89-1 [165 kB]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-11-8 11.8.89-1 [16.4 MB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libxcb-xinput0 amd64 1.13-2~ubuntu18.04 [29.3 kB]\n",
            "Get:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-11-8 11.11.3.6-1 [248 MB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-11-8 10.9.0.58-1 [94.2 MB]\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufile-11-8 1.4.0.31-1 [474 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-11-8 10.3.0.86-1 [42.2 MB]\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-11-8 11.4.1.48-1 [52.3 MB]\n",
            "Get:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-11-8 11.7.5.86-1 [116 MB]\n",
            "Get:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-11-8 11.8.0.86-1 [102 MB]\n",
            "Get:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-11-8 11.9.0.86-1 [1,865 kB]\n",
            "Get:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-11-8 11.8.0-1 [2,514 B]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-runtime-11-8 11.8.0-1 [2,426 B]\n",
            "Get:15 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuobjdump-11-8 11.8.86-1 [165 kB]\n",
            "Get:16 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cuxxfilt-11-8 11.8.86-1 [189 kB]\n",
            "Get:17 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cccl-11-8 11.8.89-1 [1,040 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-driver-dev-11-8 11.8.89-1 [27.3 kB]\n",
            "Get:19 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cudart-dev-11-8 11.8.89-1 [820 kB]\n",
            "Get:20 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvcc-11-8 11.8.89-1 [43.5 MB]\n",
            "Get:21 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprune-11-8 11.8.86-1 [58.1 kB]\n",
            "Get:22 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-compiler-11-8 11.8.0-1 [2,428 B]\n",
            "Get:23 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-profiler-api-11-8 11.8.86-1 [18.5 kB]\n",
            "Get:24 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvrtc-dev-11-8 11.8.89-1 [13.5 MB]\n",
            "Get:25 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcublas-dev-11-8 11.11.3.6-1 [269 MB]\n",
            "Get:26 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufft-dev-11-8 10.9.0.58-1 [189 MB]\n",
            "Get:27 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcufile-dev-11-8 1.4.0.31-1 [1,062 kB]\n",
            "Get:28 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcurand-dev-11-8 10.3.0.86-1 [42.9 MB]\n",
            "Get:29 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusolver-dev-11-8 11.4.1.48-1 [35.7 MB]\n",
            "Get:30 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcusparse-dev-11-8 11.7.5.86-1 [116 MB]\n",
            "Get:31 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnpp-dev-11-8 11.8.0.86-1 [100 MB]\n",
            "Get:32 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libnvjpeg-dev-11-8 11.9.0.86-1 [1,536 kB]\n",
            "Get:33 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-libraries-dev-11-8 11.8.0-1 [2,552 B]\n",
            "Get:34 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-11-8 11.8.87-1 [15.4 MB]\n",
            "Get:35 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-cupti-dev-11-8 11.8.87-1 [2,552 kB]\n",
            "Get:36 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvdisasm-11-8 11.8.86-1 [50.8 MB]\n",
            "Get:37 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-gdb-11-8 11.8.86-1 [4,138 kB]\n",
            "Get:38 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-memcheck-11-8 11.8.86-1 [142 kB]\n",
            "Get:39 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvprof-11-8 11.8.87-1 [1,959 kB]\n",
            "Get:40 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvtx-11-8 11.8.86-1 [51.3 kB]\n",
            "Get:41 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-sanitizer-11-8 11.8.86-1 [8,784 kB]\n",
            "Get:42 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-command-line-tools-11-8 11.8.0-1 [2,468 B]\n",
            "Get:43 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  nsight-compute-2022.3.0 2022.3.0.22-1 [580 MB]\n",
            "Get:44 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-compute-11-8 11.8.0-1 [3,784 B]\n",
            "Get:45 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  nsight-systems-2022.4.2 2022.4.2.1-df9881f [284 MB]\n",
            "Get:46 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-systems-11-8 11.8.0-1 [3,308 B]\n",
            "Get:47 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nsight-11-8 11.8.86-1 [119 MB]\n",
            "Get:48 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvml-dev-11-8 11.8.86-1 [81.4 kB]\n",
            "Get:49 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-nvvp-11-8 11.8.87-1 [114 MB]\n",
            "Get:50 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-visual-tools-11-8 11.8.0-1 [2,872 B]\n",
            "Get:51 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  gds-tools-11-8 1.4.0.31-1 [38.7 MB]\n",
            "Get:52 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-tools-11-8 11.8.0-1 [2,390 B]\n",
            "Get:53 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-documentation-11-8 11.8.86-1 [49.8 kB]\n",
            "Get:54 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-toolkit-11-8 11.8.0-1 [3,370 B]\n",
            "Get:55 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-demo-suite-11-8 11.8.86-1 [3,997 kB]\n",
            "Get:56 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda-11-8 11.8.0-1 [2,446 B]\n",
            "Get:57 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  cuda 11.8.0-1 [2,394 B]\n",
            "Fetched 2,713 MB in 55s (49.5 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package cuda-toolkit-11-8-config-common.\n",
            "(Reading database ... 123991 files and directories currently installed.)\n",
            "Preparing to unpack .../00-cuda-toolkit-11-8-config-common_11.8.89-1_all.deb ...\n",
            "Unpacking cuda-toolkit-11-8-config-common (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-11-8.\n",
            "Preparing to unpack .../01-cuda-cudart-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-11-8.\n",
            "Preparing to unpack .../02-cuda-nvrtc-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package libcublas-11-8.\n",
            "Preparing to unpack .../03-libcublas-11-8_11.11.3.6-1_amd64.deb ...\n",
            "Unpacking libcublas-11-8 (11.11.3.6-1) ...\n",
            "Selecting previously unselected package libcufft-11-8.\n",
            "Preparing to unpack .../04-libcufft-11-8_10.9.0.58-1_amd64.deb ...\n",
            "Unpacking libcufft-11-8 (10.9.0.58-1) ...\n",
            "Selecting previously unselected package libcufile-11-8.\n",
            "Preparing to unpack .../05-libcufile-11-8_1.4.0.31-1_amd64.deb ...\n",
            "Unpacking libcufile-11-8 (1.4.0.31-1) ...\n",
            "Selecting previously unselected package libcurand-11-8.\n",
            "Preparing to unpack .../06-libcurand-11-8_10.3.0.86-1_amd64.deb ...\n",
            "Unpacking libcurand-11-8 (10.3.0.86-1) ...\n",
            "Selecting previously unselected package libcusolver-11-8.\n",
            "Preparing to unpack .../07-libcusolver-11-8_11.4.1.48-1_amd64.deb ...\n",
            "Unpacking libcusolver-11-8 (11.4.1.48-1) ...\n",
            "Selecting previously unselected package libcusparse-11-8.\n",
            "Preparing to unpack .../08-libcusparse-11-8_11.7.5.86-1_amd64.deb ...\n",
            "Unpacking libcusparse-11-8 (11.7.5.86-1) ...\n",
            "Selecting previously unselected package libnpp-11-8.\n",
            "Preparing to unpack .../09-libnpp-11-8_11.8.0.86-1_amd64.deb ...\n",
            "Unpacking libnpp-11-8 (11.8.0.86-1) ...\n",
            "Selecting previously unselected package libnvjpeg-11-8.\n",
            "Preparing to unpack .../10-libnvjpeg-11-8_11.9.0.86-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-11-8 (11.9.0.86-1) ...\n",
            "Selecting previously unselected package cuda-libraries-11-8.\n",
            "Preparing to unpack .../11-cuda-libraries-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-runtime-11-8.\n",
            "Preparing to unpack .../12-cuda-runtime-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-runtime-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-cuobjdump-11-8.\n",
            "Preparing to unpack .../13-cuda-cuobjdump-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-cuobjdump-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-cuxxfilt-11-8.\n",
            "Preparing to unpack .../14-cuda-cuxxfilt-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-cuxxfilt-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-cccl-11-8.\n",
            "Preparing to unpack .../15-cuda-cccl-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-cccl-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-driver-dev-11-8.\n",
            "Preparing to unpack .../16-cuda-driver-dev-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-driver-dev-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-cudart-dev-11-8.\n",
            "Preparing to unpack .../17-cuda-cudart-dev-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-cudart-dev-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-nvcc-11-8.\n",
            "Preparing to unpack .../18-cuda-nvcc-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvcc-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package cuda-nvprune-11-8.\n",
            "Preparing to unpack .../19-cuda-nvprune-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-nvprune-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-compiler-11-8.\n",
            "Preparing to unpack .../20-cuda-compiler-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-compiler-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-profiler-api-11-8.\n",
            "Preparing to unpack .../21-cuda-profiler-api-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-profiler-api-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-nvrtc-dev-11-8.\n",
            "Preparing to unpack .../22-cuda-nvrtc-dev-11-8_11.8.89-1_amd64.deb ...\n",
            "Unpacking cuda-nvrtc-dev-11-8 (11.8.89-1) ...\n",
            "Selecting previously unselected package libcublas-dev-11-8.\n",
            "Preparing to unpack .../23-libcublas-dev-11-8_11.11.3.6-1_amd64.deb ...\n",
            "Unpacking libcublas-dev-11-8 (11.11.3.6-1) ...\n",
            "Selecting previously unselected package libcufft-dev-11-8.\n",
            "Preparing to unpack .../24-libcufft-dev-11-8_10.9.0.58-1_amd64.deb ...\n",
            "Unpacking libcufft-dev-11-8 (10.9.0.58-1) ...\n",
            "Selecting previously unselected package libcufile-dev-11-8.\n",
            "Preparing to unpack .../25-libcufile-dev-11-8_1.4.0.31-1_amd64.deb ...\n",
            "Unpacking libcufile-dev-11-8 (1.4.0.31-1) ...\n",
            "Selecting previously unselected package libcurand-dev-11-8.\n",
            "Preparing to unpack .../26-libcurand-dev-11-8_10.3.0.86-1_amd64.deb ...\n",
            "Unpacking libcurand-dev-11-8 (10.3.0.86-1) ...\n",
            "Selecting previously unselected package libcusolver-dev-11-8.\n",
            "Preparing to unpack .../27-libcusolver-dev-11-8_11.4.1.48-1_amd64.deb ...\n",
            "Unpacking libcusolver-dev-11-8 (11.4.1.48-1) ...\n",
            "Selecting previously unselected package libcusparse-dev-11-8.\n",
            "Preparing to unpack .../28-libcusparse-dev-11-8_11.7.5.86-1_amd64.deb ...\n",
            "Unpacking libcusparse-dev-11-8 (11.7.5.86-1) ...\n",
            "Selecting previously unselected package libnpp-dev-11-8.\n",
            "Preparing to unpack .../29-libnpp-dev-11-8_11.8.0.86-1_amd64.deb ...\n",
            "Unpacking libnpp-dev-11-8 (11.8.0.86-1) ...\n",
            "Selecting previously unselected package libnvjpeg-dev-11-8.\n",
            "Preparing to unpack .../30-libnvjpeg-dev-11-8_11.9.0.86-1_amd64.deb ...\n",
            "Unpacking libnvjpeg-dev-11-8 (11.9.0.86-1) ...\n",
            "Selecting previously unselected package cuda-libraries-dev-11-8.\n",
            "Preparing to unpack .../31-cuda-libraries-dev-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-libraries-dev-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-cupti-11-8.\n",
            "Preparing to unpack .../32-cuda-cupti-11-8_11.8.87-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-11-8 (11.8.87-1) ...\n",
            "Selecting previously unselected package cuda-cupti-dev-11-8.\n",
            "Preparing to unpack .../33-cuda-cupti-dev-11-8_11.8.87-1_amd64.deb ...\n",
            "Unpacking cuda-cupti-dev-11-8 (11.8.87-1) ...\n",
            "Selecting previously unselected package cuda-nvdisasm-11-8.\n",
            "Preparing to unpack .../34-cuda-nvdisasm-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-nvdisasm-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-gdb-11-8.\n",
            "Preparing to unpack .../35-cuda-gdb-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-gdb-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-memcheck-11-8.\n",
            "Preparing to unpack .../36-cuda-memcheck-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-memcheck-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-nvprof-11-8.\n",
            "Preparing to unpack .../37-cuda-nvprof-11-8_11.8.87-1_amd64.deb ...\n",
            "Unpacking cuda-nvprof-11-8 (11.8.87-1) ...\n",
            "Selecting previously unselected package cuda-nvtx-11-8.\n",
            "Preparing to unpack .../38-cuda-nvtx-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-nvtx-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-sanitizer-11-8.\n",
            "Preparing to unpack .../39-cuda-sanitizer-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-sanitizer-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-command-line-tools-11-8.\n",
            "Preparing to unpack .../40-cuda-command-line-tools-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-command-line-tools-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package nsight-compute-2022.3.0.\n",
            "Preparing to unpack .../41-nsight-compute-2022.3.0_2022.3.0.22-1_amd64.deb ...\n",
            "Unpacking nsight-compute-2022.3.0 (2022.3.0.22-1) ...\n",
            "Selecting previously unselected package cuda-nsight-compute-11-8.\n",
            "Preparing to unpack .../42-cuda-nsight-compute-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-compute-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../43-libxcb-xinput0_1.13-2~ubuntu18.04_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Selecting previously unselected package nsight-systems-2022.4.2.\n",
            "Preparing to unpack .../44-nsight-systems-2022.4.2_2022.4.2.1-df9881f_amd64.deb ...\n",
            "Unpacking nsight-systems-2022.4.2 (2022.4.2.1-df9881f) ...\n",
            "Selecting previously unselected package cuda-nsight-systems-11-8.\n",
            "Preparing to unpack .../45-cuda-nsight-systems-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-systems-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-nsight-11-8.\n",
            "Preparing to unpack .../46-cuda-nsight-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-nsight-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-nvml-dev-11-8.\n",
            "Preparing to unpack .../47-cuda-nvml-dev-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-nvml-dev-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-nvvp-11-8.\n",
            "Preparing to unpack .../48-cuda-nvvp-11-8_11.8.87-1_amd64.deb ...\n",
            "Unpacking cuda-nvvp-11-8 (11.8.87-1) ...\n",
            "Selecting previously unselected package cuda-visual-tools-11-8.\n",
            "Preparing to unpack .../49-cuda-visual-tools-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-visual-tools-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package gds-tools-11-8.\n",
            "Preparing to unpack .../50-gds-tools-11-8_1.4.0.31-1_amd64.deb ...\n",
            "Unpacking gds-tools-11-8 (1.4.0.31-1) ...\n",
            "Selecting previously unselected package cuda-tools-11-8.\n",
            "Preparing to unpack .../51-cuda-tools-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-tools-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-documentation-11-8.\n",
            "Preparing to unpack .../52-cuda-documentation-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-documentation-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-toolkit-11-8.\n",
            "Preparing to unpack .../53-cuda-toolkit-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-toolkit-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda-demo-suite-11-8.\n",
            "Preparing to unpack .../54-cuda-demo-suite-11-8_11.8.86-1_amd64.deb ...\n",
            "Unpacking cuda-demo-suite-11-8 (11.8.86-1) ...\n",
            "Selecting previously unselected package cuda-11-8.\n",
            "Preparing to unpack .../55-cuda-11-8_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda-11-8 (11.8.0-1) ...\n",
            "Selecting previously unselected package cuda.\n",
            "Preparing to unpack .../56-cuda_11.8.0-1_amd64.deb ...\n",
            "Unpacking cuda (11.8.0-1) ...\n",
            "Setting up cuda-nsight-11-8 (11.8.86-1) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.13-2~ubuntu18.04) ...\n",
            "Setting up cuda-nvdisasm-11-8 (11.8.86-1) ...\n",
            "Setting up gds-tools-11-8 (1.4.0.31-1) ...\n",
            "Setting up cuda-nvrtc-11-8 (11.8.89-1) ...\n",
            "Setting up cuda-nvprof-11-8 (11.8.87-1) ...\n",
            "Setting up cuda-cccl-11-8 (11.8.89-1) ...\n",
            "Setting up cuda-nvvp-11-8 (11.8.87-1) ...\n",
            "Setting up cuda-nvtx-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-nvml-dev-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-driver-dev-11-8 (11.8.89-1) ...\n",
            "Setting up cuda-cuxxfilt-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-cuobjdump-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-documentation-11-8 (11.8.86-1) ...\n",
            "Setting up nsight-compute-2022.3.0 (2022.3.0.22-1) ...\n",
            "Setting up cuda-cupti-11-8 (11.8.87-1) ...\n",
            "Setting up cuda-nsight-compute-11-8 (11.8.0-1) ...\n",
            "Setting up nsight-systems-2022.4.2 (2022.4.2.1-df9881f) ...\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2022.4.2/target-linux-x64/nsys to provide /usr/local/bin/nsys (nsys) in manual mode\n",
            "update-alternatives: using /opt/nvidia/nsight-systems/2022.4.2/host-linux-x64/nsys-ui to provide /usr/local/bin/nsys-ui (nsys-ui) in manual mode\n",
            "Setting up cuda-gdb-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-profiler-api-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-nvprune-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-nvrtc-dev-11-8 (11.8.89-1) ...\n",
            "Setting up cuda-toolkit-11-8-config-common (11.8.89-1) ...\n",
            "Setting alternatives\n",
            "update-alternatives: using /usr/local/cuda-11.8 to provide /usr/local/cuda (cuda) in auto mode\n",
            "update-alternatives: using /usr/local/cuda-11.8 to provide /usr/local/cuda-11 (cuda-11) in auto mode\n",
            "Setting up cuda-sanitizer-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-nsight-systems-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-memcheck-11-8 (11.8.86-1) ...\n",
            "Setting up libcufft-11-8 (10.9.0.58-1) ...\n",
            "Setting up libcusolver-11-8 (11.4.1.48-1) ...\n",
            "Setting up libcusolver-dev-11-8 (11.4.1.48-1) ...\n",
            "Setting up libnvjpeg-11-8 (11.9.0.86-1) ...\n",
            "Setting up libnpp-11-8 (11.8.0.86-1) ...\n",
            "Setting up cuda-cupti-dev-11-8 (11.8.87-1) ...\n",
            "Setting up libcurand-11-8 (10.3.0.86-1) ...\n",
            "Setting up libcurand-dev-11-8 (10.3.0.86-1) ...\n",
            "Setting up libcufile-11-8 (1.4.0.31-1) ...\n",
            "Setting alternatives\n",
            "update-alternatives: using /usr/local/cuda-11.8/gds/cufile.json to provide /etc/cufile.json (cufile.json) in auto mode\n",
            "Setting up cuda-cudart-11-8 (11.8.89-1) ...\n",
            "Setting up libcufft-dev-11-8 (10.9.0.58-1) ...\n",
            "Setting up libnvjpeg-dev-11-8 (11.9.0.86-1) ...\n",
            "Setting up cuda-cudart-dev-11-8 (11.8.89-1) ...\n",
            "Setting up libcusparse-11-8 (11.7.5.86-1) ...\n",
            "Setting up libcublas-11-8 (11.11.3.6-1) ...\n",
            "Setting up cuda-command-line-tools-11-8 (11.8.0-1) ...\n",
            "Setting up libcublas-dev-11-8 (11.11.3.6-1) ...\n",
            "Setting up libnpp-dev-11-8 (11.8.0.86-1) ...\n",
            "Setting up libcusparse-dev-11-8 (11.7.5.86-1) ...\n",
            "Setting up libcufile-dev-11-8 (1.4.0.31-1) ...\n",
            "Setting up cuda-libraries-dev-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-nvcc-11-8 (11.8.89-1) ...\n",
            "Setting up cuda-libraries-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-runtime-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-demo-suite-11-8 (11.8.86-1) ...\n",
            "Setting up cuda-compiler-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-visual-tools-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-tools-11-8 (11.8.0-1) ...\n",
            "Setting up cuda-toolkit-11-8 (11.8.0-1) ...\n",
            "Setting alternatives\n",
            "Setting up cuda-11-8 (11.8.0-1) ...\n",
            "Setting up cuda (11.8.0-1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGIfzn0sfL5i",
        "outputId": "21ff2059-9162-4a79-b65e-18f343930ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [1 InRelease 0 B/3,\r0% [Connecting to archive.ubuntu.com] [Waiting for headers] [Waiting for header\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [Waiting for h\r                                                                               \rGet:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com] [2 InRelease 1\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [1 InRelease gpgv 3,626 B] [Connecting to archive.ubuntu.com (185.125.190.36\r                                                                               \rGet:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Hit:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [1,038 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [83.3 kB]\n",
            "Get:14 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [3,071 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,563 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,262 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,497 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [38.5 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,303 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,338 kB]\n",
            "Fetched 14.4 MB in 4s (3,335 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52UwFZTLfWEA",
        "outputId": "32e40d5a-4398-4c2f-a899-ef46214f818e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "Calculating upgrade... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following packages have been kept back:\n",
            "  libcudnn8 libcudnn8-dev libnccl-dev libnccl2\n",
            "The following packages will be upgraded:\n",
            "  libexpat1 libexpat1-dev libice-dev libice6 libjbig-dev libjbig0 login passwd\n",
            "  xserver-common xserver-xorg-core-hwe-18.04\n",
            "10 upgraded, 0 newly installed, 0 to remove and 4 not upgraded.\n",
            "Need to get 2,833 kB of archives.\n",
            "After this operation, 5,120 B of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 login amd64 1:4.5-1ubuntu2.5 [307 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 passwd amd64 1:4.5-1ubuntu2.5 [818 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1-dev amd64 2.2.5-3ubuntu0.9 [124 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libexpat1 amd64 2.2.5-3ubuntu0.9 [82.8 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libice-dev amd64 2:1.0.9-2ubuntu0.18.04.1 [47.2 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libice6 amd64 2:1.0.9-2ubuntu0.18.04.1 [40.7 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-common all 2:1.19.6-1ubuntu4.12 [27.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 xserver-xorg-core-hwe-18.04 amd64 2:1.20.8-2ubuntu2.2~18.04.8 [1,335 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjbig-dev amd64 2.1-3.1ubuntu0.18.04.1 [25.3 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 libjbig0 amd64 2.1-3.1ubuntu0.18.04.1 [27.0 kB]\n",
            "Fetched 2,833 kB in 2s (1,855 kB/s)\n",
            "(Reading database ... 129170 files and directories currently installed.)\n",
            "Preparing to unpack .../login_1%3a4.5-1ubuntu2.5_amd64.deb ...\n",
            "Unpacking login (1:4.5-1ubuntu2.5) over (1:4.5-1ubuntu2.3) ...\n",
            "Setting up login (1:4.5-1ubuntu2.5) ...\n",
            "(Reading database ... 129170 files and directories currently installed.)\n",
            "Preparing to unpack .../passwd_1%3a4.5-1ubuntu2.5_amd64.deb ...\n",
            "Unpacking passwd (1:4.5-1ubuntu2.5) over (1:4.5-1ubuntu2.3) ...\n",
            "Setting up passwd (1:4.5-1ubuntu2.5) ...\n",
            "(Reading database ... 129170 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libexpat1-dev_2.2.5-3ubuntu0.9_amd64.deb ...\n",
            "Unpacking libexpat1-dev:amd64 (2.2.5-3ubuntu0.9) over (2.2.5-3ubuntu0.8) ...\n",
            "Preparing to unpack .../1-libexpat1_2.2.5-3ubuntu0.9_amd64.deb ...\n",
            "Unpacking libexpat1:amd64 (2.2.5-3ubuntu0.9) over (2.2.5-3ubuntu0.8) ...\n",
            "Preparing to unpack .../2-libice-dev_2%3a1.0.9-2ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.9-2ubuntu0.18.04.1) over (2:1.0.9-2) ...\n",
            "Preparing to unpack .../3-libice6_2%3a1.0.9-2ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) over (2:1.0.9-2) ...\n",
            "Preparing to unpack .../4-xserver-common_2%3a1.19.6-1ubuntu4.12_all.deb ...\n",
            "Unpacking xserver-common (2:1.19.6-1ubuntu4.12) over (2:1.19.6-1ubuntu4.11) ...\n",
            "Preparing to unpack .../5-xserver-xorg-core-hwe-18.04_2%3a1.20.8-2ubuntu2.2~18.04.8_amd64.deb ...\n",
            "Unpacking xserver-xorg-core-hwe-18.04 (2:1.20.8-2ubuntu2.2~18.04.8) over (2:1.20.8-2ubuntu2.2~18.04.7) ...\n",
            "Preparing to unpack .../6-libjbig-dev_2.1-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libjbig-dev:amd64 (2.1-3.1ubuntu0.18.04.1) over (2.1-3.1build1) ...\n",
            "Preparing to unpack .../7-libjbig0_2.1-3.1ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) over (2.1-3.1build1) ...\n",
            "Setting up libexpat1:amd64 (2.2.5-3ubuntu0.9) ...\n",
            "Setting up xserver-common (2:1.19.6-1ubuntu4.12) ...\n",
            "Setting up libjbig0:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libjbig-dev:amd64 (2.1-3.1ubuntu0.18.04.1) ...\n",
            "Setting up libice6:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
            "Setting up libexpat1-dev:amd64 (2.2.5-3ubuntu0.9) ...\n",
            "Setting up xserver-xorg-core-hwe-18.04 (2:1.20.8-2ubuntu2.2~18.04.8) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.9-2ubuntu0.18.04.1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.6) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyVp_VlZDs8n",
        "outputId": "35ba14a5-7fb9-4d80-ef3d-1f92b98c5852"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.9.2)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.6)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.19.6)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.27.0)\n",
            "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.1.1)\n",
            "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow) (21.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.1.0)\n",
            "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.50.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.14.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow) (3.0.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peu8hgOlFwP5",
        "outputId": "3ee28da6-4f80-4a2c-9bb3-5eb431354589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-gpu\n",
            "  Downloading tensorflow_gpu-2.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 5.4 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.50.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 37.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.27.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (57.4.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (14.0.6)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 59.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.14.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.11.23-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (4.1.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.21.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (21.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow-gpu) (0.38.4)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow-gpu) (1.5.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.14.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.12,>=2.11->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.10.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow-gpu) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->tensorflow-gpu) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow-gpu\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires flatbuffers<2,>=1.12, but you have flatbuffers 22.11.23 which is incompatible.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorboard<2.10,>=2.9, but you have tensorboard 2.11.0 which is incompatible.\n",
            "tensorflow 2.9.2 requires tensorflow-estimator<2.10.0,>=2.9.0rc0, but you have tensorflow-estimator 2.11.0 which is incompatible.\u001b[0m\n",
            "Successfully installed flatbuffers-22.11.23 keras-2.11.0 tensorboard-2.11.0 tensorflow-estimator-2.11.0 tensorflow-gpu-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Fixed Batch Normalization"
      ],
      "metadata": {
        "id": "C-0-jH7lAFVh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3NHlvL-d_x57"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Layer, InputSpec\n",
        "from keras import initializers, regularizers\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FixedBatchNormalization(Layer):\n",
        "\n",
        "    def __init__(self, epsilon=1e-3, axis=-1,\n",
        "                 weights=None, beta_init='zero', gamma_init='one',\n",
        "                 gamma_regularizer=None, beta_regularizer=None, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.beta_init = initializers.get(beta_init)\n",
        "        self.gamma_init = initializers.get(gamma_init)\n",
        "        self.epsilon = epsilon\n",
        "        self.axis = axis\n",
        "        self.gamma_regularizer = regularizers.get(gamma_regularizer)\n",
        "        self.beta_regularizer = regularizers.get(beta_regularizer)\n",
        "        self.initial_weights = weights\n",
        "        super(FixedBatchNormalization, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.input_spec = [InputSpec(shape=input_shape)]\n",
        "        shape = (input_shape[self.axis],)\n",
        "\n",
        "        self.gamma = self.add_weight(shape,\n",
        "                                     initializer=self.gamma_init,\n",
        "                                     regularizer=self.gamma_regularizer,\n",
        "                                     name='{}_gamma'.format(self.name),\n",
        "                                     trainable=False)\n",
        "        self.beta = self.add_weight(shape,\n",
        "                                    initializer=self.beta_init,\n",
        "                                    regularizer=self.beta_regularizer,\n",
        "                                    name='{}_beta'.format(self.name),\n",
        "                                    trainable=False)\n",
        "        self.running_mean = self.add_weight(shape, initializer='zero',\n",
        "                                            name='{}_running_mean'.format(self.name),\n",
        "                                            trainable=False)\n",
        "        self.running_std = self.add_weight(shape, initializer='one',\n",
        "                                           name='{}_running_std'.format(self.name),\n",
        "                                           trainable=False)\n",
        "\n",
        "        if self.initial_weights is not None:\n",
        "            self.set_weights(self.initial_weights)\n",
        "            del self.initial_weights\n",
        "\n",
        "        self.built = True\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert self.built, 'Layer must be built before being called'\n",
        "        input_shape = K.int_shape(x)\n",
        "\n",
        "        reduction_axes = list(range(len(input_shape)))\n",
        "        del reduction_axes[self.axis]\n",
        "        broadcast_shape = [1] * len(input_shape)\n",
        "        broadcast_shape[self.axis] = input_shape[self.axis]\n",
        "\n",
        "        if sorted(reduction_axes) == range(K.ndim(x))[:-1]:\n",
        "            x_normed = K.batch_normalization(\n",
        "                x, self.running_mean, self.running_std,\n",
        "                self.beta, self.gamma,\n",
        "                epsilon=self.epsilon)\n",
        "        else:\n",
        "            # need broadcasting\n",
        "            broadcast_running_mean = K.reshape(self.running_mean, broadcast_shape)\n",
        "            broadcast_running_std = K.reshape(self.running_std, broadcast_shape)\n",
        "            broadcast_beta = K.reshape(self.beta, broadcast_shape)\n",
        "            broadcast_gamma = K.reshape(self.gamma, broadcast_shape)\n",
        "            x_normed = K.batch_normalization(\n",
        "                x, broadcast_running_mean, broadcast_running_std,\n",
        "                broadcast_beta, broadcast_gamma,\n",
        "                epsilon=self.epsilon)\n",
        "\n",
        "        return x_normed\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'epsilon': self.epsilon,\n",
        "                  'axis': self.axis,\n",
        "                  'gamma_regularizer': self.gamma_regularizer.get_config() if self.gamma_regularizer else None,\n",
        "                  'beta_regularizer': self.beta_regularizer.get_config() if self.beta_regularizer else None}\n",
        "        base_config = super(FixedBatchNormalization, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "zmgcUs-nGqAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if K.backend() == 'tensorflow':\n",
        "    import tensorflow as tf\n",
        "\n",
        "class RoiPoolingConv(Layer):\n",
        "    '''ROI pooling layer for 2D inputs.\n",
        "    See Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,\n",
        "    K. He, X. Zhang, S. Ren, J. Sun\n",
        "    # Arguments\n",
        "        pool_size: int\n",
        "            Size of pooling region to use. pool_size = 7 will result in a 7x7 region.\n",
        "        num_rois: number of regions of interest to be used\n",
        "    # Input shape\n",
        "        list of two 4D tensors [X_img,X_roi] with shape:\n",
        "        X_img:\n",
        "        `(1, channels, rows, cols)` if dim_ordering='th'\n",
        "        or 4D tensor with shape:\n",
        "        `(1, rows, cols, channels)` if dim_ordering='tf'.\n",
        "        X_roi:\n",
        "        `(1,num_rois,4)` list of rois, with ordering (x,y,w,h)\n",
        "    # Output shape\n",
        "        3D tensor with shape:\n",
        "        `(1, num_rois, channels, pool_size, pool_size)`\n",
        "    '''\n",
        "    def __init__(self, pool_size, num_rois, **kwargs):\n",
        "\n",
        "        self.dim_ordering = K.image_dim_ordering()\n",
        "        assert self.dim_ordering in {'tf', 'th'}, 'dim_ordering must be in {tf, th}'\n",
        "\n",
        "        self.pool_size = pool_size\n",
        "        self.num_rois = num_rois\n",
        "\n",
        "        super(RoiPoolingConv, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if self.dim_ordering == 'th':\n",
        "            self.nb_channels = input_shape[0][1]\n",
        "        elif self.dim_ordering == 'tf':\n",
        "            self.nb_channels = input_shape[0][3]\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        if self.dim_ordering == 'th':\n",
        "            return None, self.num_rois, self.nb_channels, self.pool_size, self.pool_size\n",
        "        else:\n",
        "            return None, self.num_rois, self.pool_size, self.pool_size, self.nb_channels\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "\n",
        "        assert(len(x) == 2)\n",
        "\n",
        "        img = x[0]\n",
        "        rois = x[1]\n",
        "\n",
        "        input_shape = K.shape(img)\n",
        "\n",
        "        outputs = []\n",
        "\n",
        "        for roi_idx in range(self.num_rois):\n",
        "\n",
        "            x = rois[0, roi_idx, 0]\n",
        "            y = rois[0, roi_idx, 1]\n",
        "            w = rois[0, roi_idx, 2]\n",
        "            h = rois[0, roi_idx, 3]\n",
        "            \n",
        "            row_length = w / float(self.pool_size)\n",
        "            col_length = h / float(self.pool_size)\n",
        "\n",
        "            num_pool_regions = self.pool_size\n",
        "\n",
        "            #NOTE: the RoiPooling implementation differs between theano and tensorflow due to the lack of a resize op\n",
        "            # in theano. The theano implementation is much less efficient and leads to long compile times\n",
        "\n",
        "            if self.dim_ordering == 'th':\n",
        "                for jy in range(num_pool_regions):\n",
        "                    for ix in range(num_pool_regions):\n",
        "                        x1 = x + ix * row_length\n",
        "                        x2 = x1 + row_length\n",
        "                        y1 = y + jy * col_length\n",
        "                        y2 = y1 + col_length\n",
        "\n",
        "                        x1 = K.cast(x1, 'int32')\n",
        "                        x2 = K.cast(x2, 'int32')\n",
        "                        y1 = K.cast(y1, 'int32')\n",
        "                        y2 = K.cast(y2, 'int32')\n",
        "\n",
        "                        x2 = x1 + K.maximum(1,x2-x1)\n",
        "                        y2 = y1 + K.maximum(1,y2-y1)\n",
        "                        \n",
        "                        new_shape = [input_shape[0], input_shape[1],\n",
        "                                     y2 - y1, x2 - x1]\n",
        "\n",
        "                        x_crop = img[:, :, y1:y2, x1:x2]\n",
        "                        xm = K.reshape(x_crop, new_shape)\n",
        "                        pooled_val = K.max(xm, axis=(2, 3))\n",
        "                        outputs.append(pooled_val)\n",
        "\n",
        "            elif self.dim_ordering == 'tf':\n",
        "                x = K.cast(x, 'int32')\n",
        "                y = K.cast(y, 'int32')\n",
        "                w = K.cast(w, 'int32')\n",
        "                h = K.cast(h, 'int32')\n",
        "\n",
        "                rs = tf.image.resize_images(img[:, y:y+h, x:x+w, :], (self.pool_size, self.pool_size))\n",
        "                outputs.append(rs)\n",
        "\n",
        "        final_output = K.concatenate(outputs, axis=0)\n",
        "        final_output = K.reshape(final_output, (1, self.num_rois, self.pool_size, self.pool_size, self.nb_channels))\n",
        "\n",
        "        if self.dim_ordering == 'th':\n",
        "            final_output = K.permute_dimensions(final_output, (0, 1, 4, 2, 3))\n",
        "        else:\n",
        "            final_output = K.permute_dimensions(final_output, (0, 1, 2, 3, 4))\n",
        "\n",
        "        return final_output\n",
        "    \n",
        "    \n",
        "    def get_config(self):\n",
        "        config = {'pool_size': self.pool_size,\n",
        "                  'num_rois': self.num_rois}\n",
        "        base_config = super(RoiPoolingConv, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "metadata": {
        "id": "OlVCqFDqTUU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "class Config:\n",
        "\n",
        "\tdef __init__(self):\n",
        "\n",
        "\t\tself.verbose = True\n",
        "\n",
        "\t\tself.network = 'resnet50'\n",
        "\n",
        "\t\t# setting for data augmentation\n",
        "\t\tself.use_horizontal_flips = False\n",
        "\t\tself.use_vertical_flips = False\n",
        "\t\tself.rot_90 = False\n",
        "\n",
        "\t\t# anchor box scales\n",
        "\t\tself.anchor_box_scales = [128, 256, 512]\n",
        "\n",
        "\t\t# anchor box ratios\n",
        "\t\tself.anchor_box_ratios = [[1, 1], [1./math.sqrt(2), 2./math.sqrt(2)], [2./math.sqrt(2), 1./math.sqrt(2)]]\n",
        "\n",
        "\t\t# size to resize the smallest side of the image\n",
        "\t\tself.im_size = 600\n",
        "\n",
        "\t\t# image channel-wise mean to subtract\n",
        "\t\tself.img_channel_mean = [103.939, 116.779, 123.68]\n",
        "\t\tself.img_scaling_factor = 1.0\n",
        "\n",
        "\t\t# number of ROIs at once\n",
        "\t\tself.num_rois = 4\n",
        "\n",
        "\t\t# stride at the RPN (this depends on the network configuration)\n",
        "\t\tself.rpn_stride = 16\n",
        "\n",
        "\t\tself.balanced_classes = False\n",
        "\n",
        "\t\t# scaling the stdev\n",
        "\t\tself.std_scaling = 4.0\n",
        "\t\tself.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]\n",
        "\n",
        "\t\t# overlaps for RPN\n",
        "\t\tself.rpn_min_overlap = 0.3\n",
        "\t\tself.rpn_max_overlap = 0.7\n",
        "\n",
        "\t\t# overlaps for classifier ROIs\n",
        "\t\tself.classifier_min_overlap = 0.1\n",
        "\t\tself.classifier_max_overlap = 0.5\n",
        "\n",
        "\t\t# placeholder for the class mapping, automatically generated by the parser\n",
        "\t\tself.class_mapping = None\n",
        "\n",
        "\t\t#location of pretrained weights for the base network \n",
        "\t\t# weight files can be found at:\n",
        "\t\t# https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_th_dim_ordering_th_kernels_notop.h5\n",
        "\t\t# https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "\t\tself.model_path = 'model_frcnn.vgg.hdf5'"
      ],
      "metadata": {
        "id": "fzzYJ1hqTfNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "def augment(img_data, config, augment=True):\n",
        "\tassert 'filepath' in img_data\n",
        "\tassert 'bboxes' in img_data\n",
        "\tassert 'width' in img_data\n",
        "\tassert 'height' in img_data\n",
        "\n",
        "\timg_data_aug = copy.deepcopy(img_data)\n",
        "\n",
        "\timg = cv2.imread(img_data_aug['filepath'])\n",
        "\n",
        "\tif augment:\n",
        "\t\trows, cols = img.shape[:2]\n",
        "\n",
        "\t\tif config.use_horizontal_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\tbbox['x1'] = cols - x2\n",
        "\n",
        "\t\tif config.use_vertical_flips and np.random.randint(0, 2) == 0:\n",
        "\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\tbbox['y1'] = rows - y2\n",
        "\n",
        "\t\tif config.rot_90:\n",
        "\t\t\tangle = np.random.choice([0,90,180,270],1)[0]\n",
        "\t\t\tif angle == 270:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 0)\n",
        "\t\t\telif angle == 180:\n",
        "\t\t\t\timg = cv2.flip(img, -1)\n",
        "\t\t\telif angle == 90:\n",
        "\t\t\t\timg = np.transpose(img, (1,0,2))\n",
        "\t\t\t\timg = cv2.flip(img, 1)\n",
        "\t\t\telif angle == 0:\n",
        "\t\t\t\tpass\n",
        "\n",
        "\t\t\tfor bbox in img_data_aug['bboxes']:\n",
        "\t\t\t\tx1 = bbox['x1']\n",
        "\t\t\t\tx2 = bbox['x2']\n",
        "\t\t\t\ty1 = bbox['y1']\n",
        "\t\t\t\ty2 = bbox['y2']\n",
        "\t\t\t\tif angle == 270:\n",
        "\t\t\t\t\tbbox['x1'] = y1\n",
        "\t\t\t\t\tbbox['x2'] = y2\n",
        "\t\t\t\t\tbbox['y1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = cols - x1\n",
        "\t\t\t\telif angle == 180:\n",
        "\t\t\t\t\tbbox['x2'] = cols - x1\n",
        "\t\t\t\t\tbbox['x1'] = cols - x2\n",
        "\t\t\t\t\tbbox['y2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = rows - y2\n",
        "\t\t\t\telif angle == 90:\n",
        "\t\t\t\t\tbbox['x1'] = rows - y2\n",
        "\t\t\t\t\tbbox['x2'] = rows - y1\n",
        "\t\t\t\t\tbbox['y1'] = x1\n",
        "\t\t\t\t\tbbox['y2'] = x2        \n",
        "\t\t\t\telif angle == 0:\n",
        "\t\t\t\t\tpass\n",
        "\n",
        "\timg_data_aug['width'] = img.shape[1]\n",
        "\timg_data_aug['height'] = img.shape[0]\n",
        "\treturn img_data_aug, img"
      ],
      "metadata": {
        "id": "nGtCQ6MuTp9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def union(au, bu, area_intersection):\n",
        "\tarea_a = (au[2] - au[0]) * (au[3] - au[1])\n",
        "\tarea_b = (bu[2] - bu[0]) * (bu[3] - bu[1])\n",
        "\tarea_union = area_a + area_b - area_intersection\n",
        "\treturn area_union\n",
        "\n",
        "\n",
        "def intersection(ai, bi):\n",
        "\tx = max(ai[0], bi[0])\n",
        "\ty = max(ai[1], bi[1])\n",
        "\tw = min(ai[2], bi[2]) - x\n",
        "\th = min(ai[3], bi[3]) - y\n",
        "\tif w < 0 or h < 0:\n",
        "\t\treturn 0\n",
        "\treturn w*h\n",
        "\n",
        "\n",
        "def iou(a, b):\n",
        "\t# a and b should be (x1,y1,x2,y2)\n",
        "\n",
        "\tif a[0] >= a[2] or a[1] >= a[3] or b[0] >= b[2] or b[1] >= b[3]:\n",
        "\t\treturn 0.0\n",
        "\n",
        "\tarea_i = intersection(a, b)\n",
        "\tarea_u = union(a, b, area_i)\n",
        "\n",
        "\treturn float(area_i) / float(area_u + 1e-6)\n",
        "\n",
        "\n",
        "def get_new_img_size(width, height, img_min_side=600):\n",
        "\tif width <= height:\n",
        "\t\tf = float(img_min_side) / width\n",
        "\t\tresized_height = int(f * height)\n",
        "\t\tresized_width = img_min_side\n",
        "\telse:\n",
        "\t\tf = float(img_min_side) / height\n",
        "\t\tresized_width = int(f * width)\n",
        "\t\tresized_height = img_min_side\n",
        "\n",
        "\treturn resized_width, resized_height\n",
        "\n",
        "\n",
        "class SampleSelector:\n",
        "\tdef __init__(self, class_count):\n",
        "\t\t# ignore classes that have zero samples\n",
        "\t\tself.classes = [b for b in class_count.keys() if class_count[b] > 0]\n",
        "\t\tself.class_cycle = itertools.cycle(self.classes)\n",
        "\t\tself.curr_class = next(self.class_cycle)\n",
        "\n",
        "\tdef skip_sample_for_balanced_class(self, img_data):\n",
        "\n",
        "\t\tclass_in_img = False\n",
        "\n",
        "\t\tfor bbox in img_data['bboxes']:\n",
        "\n",
        "\t\t\tcls_name = bbox['class']\n",
        "\n",
        "\t\t\tif cls_name == self.curr_class:\n",
        "\t\t\t\tclass_in_img = True\n",
        "\t\t\t\tself.curr_class = next(self.class_cycle)\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\tif class_in_img:\n",
        "\t\t\treturn False\n",
        "\t\telse:\n",
        "\t\t\treturn True\n",
        "\n",
        "\n",
        "def calc_rpn(C, img_data, width, height, resized_width, resized_height, img_length_calc_function):\n",
        "\n",
        "\tdownscale = float(C.rpn_stride)\n",
        "\tanchor_sizes = C.anchor_box_scales\n",
        "\tanchor_ratios = C.anchor_box_ratios\n",
        "\tnum_anchors = len(anchor_sizes) * len(anchor_ratios)\t\n",
        "\n",
        "\t# calculate the output map size based on the network architecture\n",
        "\n",
        "\t(output_width, output_height) = img_length_calc_function(resized_width, resized_height)\n",
        "\n",
        "\tn_anchratios = len(anchor_ratios)\n",
        "\t\n",
        "\t# initialise empty output objectives\n",
        "\ty_rpn_overlap = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_is_box_valid = np.zeros((output_height, output_width, num_anchors))\n",
        "\ty_rpn_regr = np.zeros((output_height, output_width, num_anchors * 4))\n",
        "\n",
        "\tnum_bboxes = len(img_data['bboxes'])\n",
        "\n",
        "\tnum_anchors_for_bbox = np.zeros(num_bboxes).astype(int)\n",
        "\tbest_anchor_for_bbox = -1*np.ones((num_bboxes, 4)).astype(int)\n",
        "\tbest_iou_for_bbox = np.zeros(num_bboxes).astype(np.float32)\n",
        "\tbest_x_for_bbox = np.zeros((num_bboxes, 4)).astype(int)\n",
        "\tbest_dx_for_bbox = np.zeros((num_bboxes, 4)).astype(np.float32)\n",
        "\n",
        "\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\tgta = np.zeros((num_bboxes, 4))\n",
        "\tfor bbox_num, bbox in enumerate(img_data['bboxes']):\n",
        "\t\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\t\tgta[bbox_num, 0] = bbox['x1'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 1] = bbox['x2'] * (resized_width / float(width))\n",
        "\t\tgta[bbox_num, 2] = bbox['y1'] * (resized_height / float(height))\n",
        "\t\tgta[bbox_num, 3] = bbox['y2'] * (resized_height / float(height))\n",
        "\t\n",
        "\t# rpn ground truth\n",
        "\n",
        "\tfor anchor_size_idx in range(len(anchor_sizes)):\n",
        "\t\tfor anchor_ratio_idx in range(n_anchratios):\n",
        "\t\t\tanchor_x = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][0]\n",
        "\t\t\tanchor_y = anchor_sizes[anchor_size_idx] * anchor_ratios[anchor_ratio_idx][1]\t\n",
        "\t\t\t\n",
        "\t\t\tfor ix in range(output_width):\t\t\t\t\t\n",
        "\t\t\t\t# x-coordinates of the current anchor box\t\n",
        "\t\t\t\tx1_anc = downscale * (ix + 0.5) - anchor_x / 2\n",
        "\t\t\t\tx2_anc = downscale * (ix + 0.5) + anchor_x / 2\t\n",
        "\t\t\t\t\n",
        "\t\t\t\t# ignore boxes that go across image boundaries\t\t\t\t\t\n",
        "\t\t\t\tif x1_anc < 0 or x2_anc > resized_width:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\t\t\n",
        "\t\t\t\tfor jy in range(output_height):\n",
        "\n",
        "\t\t\t\t\t# y-coordinates of the current anchor box\n",
        "\t\t\t\t\ty1_anc = downscale * (jy + 0.5) - anchor_y / 2\n",
        "\t\t\t\t\ty2_anc = downscale * (jy + 0.5) + anchor_y / 2\n",
        "\n",
        "\t\t\t\t\t# ignore boxes that go across image boundaries\n",
        "\t\t\t\t\tif y1_anc < 0 or y2_anc > resized_height:\n",
        "\t\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t\t# bbox_type indicates whether an anchor should be a target \n",
        "\t\t\t\t\tbbox_type = 'neg'\n",
        "\n",
        "\t\t\t\t\t# this is the best IOU for the (x,y) coord and the current anchor\n",
        "\t\t\t\t\t# note that this is different from the best IOU for a GT bbox\n",
        "\t\t\t\t\tbest_iou_for_loc = 0.0\n",
        "\n",
        "\t\t\t\t\tfor bbox_num in range(num_bboxes):\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\t# get IOU of the current GT box and the current anchor box\n",
        "\t\t\t\t\t\tcurr_iou = iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1_anc, y1_anc, x2_anc, y2_anc])\n",
        "\t\t\t\t\t\t# calculate the regression targets if they will be needed\n",
        "\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num] or curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\tcx = (gta[bbox_num, 0] + gta[bbox_num, 1]) / 2.0\n",
        "\t\t\t\t\t\t\tcy = (gta[bbox_num, 2] + gta[bbox_num, 3]) / 2.0\n",
        "\t\t\t\t\t\t\tcxa = (x1_anc + x2_anc)/2.0\n",
        "\t\t\t\t\t\t\tcya = (y1_anc + y2_anc)/2.0\n",
        "\n",
        "\t\t\t\t\t\t\ttx = (cx - cxa) / (x2_anc - x1_anc)\n",
        "\t\t\t\t\t\t\tty = (cy - cya) / (y2_anc - y1_anc)\n",
        "\t\t\t\t\t\t\ttw = np.log((gta[bbox_num, 1] - gta[bbox_num, 0]) / (x2_anc - x1_anc))\n",
        "\t\t\t\t\t\t\tth = np.log((gta[bbox_num, 3] - gta[bbox_num, 2]) / (y2_anc - y1_anc))\n",
        "\t\t\t\t\t\t\n",
        "\t\t\t\t\t\tif img_data['bboxes'][bbox_num]['class'] != 'bg':\n",
        "\n",
        "\t\t\t\t\t\t\t# all GT boxes should be mapped to an anchor box, so we keep track of which anchor box was best\n",
        "\t\t\t\t\t\t\tif curr_iou > best_iou_for_bbox[bbox_num]:\n",
        "\t\t\t\t\t\t\t\tbest_anchor_for_bbox[bbox_num] = [jy, ix, anchor_ratio_idx, anchor_size_idx]\n",
        "\t\t\t\t\t\t\t\tbest_iou_for_bbox[bbox_num] = curr_iou\n",
        "\t\t\t\t\t\t\t\tbest_x_for_bbox[bbox_num,:] = [x1_anc, x2_anc, y1_anc, y2_anc]\n",
        "\t\t\t\t\t\t\t\tbest_dx_for_bbox[bbox_num,:] = [tx, ty, tw, th]\n",
        "\n",
        "\t\t\t\t\t\t\t# we set the anchor to positive if the IOU is >0.7 (it does not matter if there was another better box, it just indicates overlap)\n",
        "\t\t\t\t\t\t\tif curr_iou > C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\tbbox_type = 'pos'\n",
        "\t\t\t\t\t\t\t\tnum_anchors_for_bbox[bbox_num] += 1\n",
        "\t\t\t\t\t\t\t\t# we update the regression layer target if this IOU is the best for the current (x,y) and anchor position\n",
        "\t\t\t\t\t\t\t\tif curr_iou > best_iou_for_loc:\n",
        "\t\t\t\t\t\t\t\t\tbest_iou_for_loc = curr_iou\n",
        "\t\t\t\t\t\t\t\t\tbest_regr = (tx, ty, tw, th)\n",
        "\n",
        "\t\t\t\t\t\t\t# if the IOU is >0.3 and <0.7, it is ambiguous and no included in the objective\n",
        "\t\t\t\t\t\t\tif C.rpn_min_overlap < curr_iou < C.rpn_max_overlap:\n",
        "\t\t\t\t\t\t\t\t# gray zone between neg and pos\n",
        "\t\t\t\t\t\t\t\tif bbox_type != 'pos':\n",
        "\t\t\t\t\t\t\t\t\tbbox_type = 'neutral'\n",
        "\n",
        "\t\t\t\t\t# turn on or off outputs depending on IOUs\n",
        "\t\t\t\t\tif bbox_type == 'neg':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'neutral':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 0\n",
        "\t\t\t\t\telif bbox_type == 'pos':\n",
        "\t\t\t\t\t\ty_is_box_valid[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\ty_rpn_overlap[jy, ix, anchor_ratio_idx + n_anchratios * anchor_size_idx] = 1\n",
        "\t\t\t\t\t\tstart = 4 * (anchor_ratio_idx + n_anchratios * anchor_size_idx)\n",
        "\t\t\t\t\t\ty_rpn_regr[jy, ix, start:start+4] = best_regr\n",
        "\n",
        "\t# we ensure that every bbox has at least one positive RPN region\n",
        "\n",
        "\tfor idx in range(num_anchors_for_bbox.shape[0]):\n",
        "\t\tif num_anchors_for_bbox[idx] == 0:\n",
        "\t\t\t# no box with an IOU greater than zero ...\n",
        "\t\t\tif best_anchor_for_bbox[idx, 0] == -1:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\ty_is_box_valid[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\ty_rpn_overlap[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], best_anchor_for_bbox[idx,2] + n_anchratios *\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,3]] = 1\n",
        "\t\t\tstart = 4 * (best_anchor_for_bbox[idx,2] + n_anchratios * best_anchor_for_bbox[idx,3])\n",
        "\t\t\ty_rpn_regr[\n",
        "\t\t\t\tbest_anchor_for_bbox[idx,0], best_anchor_for_bbox[idx,1], start:start+4] = best_dx_for_bbox[idx, :]\n",
        "\n",
        "\ty_rpn_overlap = np.transpose(y_rpn_overlap, (2, 0, 1))\n",
        "\ty_rpn_overlap = np.expand_dims(y_rpn_overlap, axis=0)\n",
        "\n",
        "\ty_is_box_valid = np.transpose(y_is_box_valid, (2, 0, 1))\n",
        "\ty_is_box_valid = np.expand_dims(y_is_box_valid, axis=0)\n",
        "\n",
        "\ty_rpn_regr = np.transpose(y_rpn_regr, (2, 0, 1))\n",
        "\ty_rpn_regr = np.expand_dims(y_rpn_regr, axis=0)\n",
        "\n",
        "\tpos_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 1, y_is_box_valid[0, :, :, :] == 1))\n",
        "\tneg_locs = np.where(np.logical_and(y_rpn_overlap[0, :, :, :] == 0, y_is_box_valid[0, :, :, :] == 1))\n",
        "\n",
        "\tnum_pos = len(pos_locs[0])\n",
        "\n",
        "\t# one issue is that the RPN has many more negative than positive regions, so we turn off some of the negative\n",
        "\t# regions. We also limit it to 256 regions.\n",
        "\tnum_regions = 256\n",
        "\n",
        "\tif len(pos_locs[0]) > num_regions/2:\n",
        "\t\tval_locs = random.sample(range(len(pos_locs[0])), len(pos_locs[0]) - num_regions/2)\n",
        "\t\ty_is_box_valid[0, pos_locs[0][val_locs], pos_locs[1][val_locs], pos_locs[2][val_locs]] = 0\n",
        "\t\tnum_pos = num_regions/2\n",
        "\n",
        "\tif len(neg_locs[0]) + num_pos > num_regions:\n",
        "\t\tval_locs = random.sample(range(len(neg_locs[0])), len(neg_locs[0]) - num_pos)\n",
        "\t\ty_is_box_valid[0, neg_locs[0][val_locs], neg_locs[1][val_locs], neg_locs[2][val_locs]] = 0\n",
        "\n",
        "\ty_rpn_cls = np.concatenate([y_is_box_valid, y_rpn_overlap], axis=1)\n",
        "\ty_rpn_regr = np.concatenate([np.repeat(y_rpn_overlap, 4, axis=1), y_rpn_regr], axis=1)\n",
        "\n",
        "\treturn np.copy(y_rpn_cls), np.copy(y_rpn_regr)\n",
        "\n",
        "\n",
        "class threadsafe_iter:\n",
        "\t\"\"\"Takes an iterator/generator and makes it thread-safe by\n",
        "\tserializing call to the `next` method of given iterator/generator.\n",
        "\t\"\"\"\n",
        "\tdef __init__(self, it):\n",
        "\t\tself.it = it\n",
        "\t\tself.lock = threading.Lock()\n",
        "\n",
        "\tdef __iter__(self):\n",
        "\t\treturn self\n",
        "\n",
        "\tdef next(self):\n",
        "\t\twith self.lock:\n",
        "\t\t\treturn next(self.it)\t\t\n",
        "\n",
        "\t\n",
        "def threadsafe_generator(f):\n",
        "\t\"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
        "\t\"\"\"\n",
        "\tdef g(*a, **kw):\n",
        "\t\treturn threadsafe_iter(f(*a, **kw))\n",
        "\treturn g\n",
        "\n",
        "def get_anchor_gt(all_img_data, class_count, C, img_length_calc_function, backend, mode='train'):\n",
        "\n",
        "\t# The following line is not useful with Python 3.5, it is kept for the legacy\n",
        "\t# all_img_data = sorted(all_img_data)\n",
        "\n",
        "\tsample_selector = SampleSelector(class_count)\n",
        "\n",
        "\twhile True:\n",
        "\t\tif mode == 'train':\n",
        "\t\t\tnp.random.shuffle(all_img_data)\n",
        "\n",
        "\t\tfor img_data in all_img_data:\n",
        "\t\t\ttry:\n",
        "\n",
        "\t\t\t\tif C.balanced_classes and sample_selector.skip_sample_for_balanced_class(img_data):\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# read in image, and optionally add augmentation\n",
        "\n",
        "\t\t\t\tif mode == 'train':\n",
        "\t\t\t\t\timg_data_aug, x_img = data_augment.augment(img_data, C, augment=True)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\timg_data_aug, x_img = data_augment.augment(img_data, C, augment=False)\n",
        "\n",
        "\t\t\t\t(width, height) = (img_data_aug['width'], img_data_aug['height'])\n",
        "\t\t\t\t(rows, cols, _) = x_img.shape\n",
        "\n",
        "\t\t\t\tassert cols == width\n",
        "\t\t\t\tassert rows == height\n",
        "\n",
        "\t\t\t\t# get image dimensions for resizing\n",
        "\t\t\t\t(resized_width, resized_height) = get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\t\t\t\t# resize the image so that smalles side is length = 600px\n",
        "\t\t\t\tx_img = cv2.resize(x_img, (resized_width, resized_height), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\ty_rpn_cls, y_rpn_regr = calc_rpn(C, img_data_aug, width, height, resized_width, resized_height, img_length_calc_function)\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\n",
        "\t\t\t\t# Zero-center by mean pixel, and preprocess image\n",
        "\n",
        "\t\t\t\tx_img = x_img[:,:, (2, 1, 0)]  # BGR -> RGB\n",
        "\t\t\t\tx_img = x_img.astype(np.float32)\n",
        "\t\t\t\tx_img[:, :, 0] -= C.img_channel_mean[0]\n",
        "\t\t\t\tx_img[:, :, 1] -= C.img_channel_mean[1]\n",
        "\t\t\t\tx_img[:, :, 2] -= C.img_channel_mean[2]\n",
        "\t\t\t\tx_img /= C.img_scaling_factor\n",
        "\n",
        "\t\t\t\tx_img = np.transpose(x_img, (2, 0, 1))\n",
        "\t\t\t\tx_img = np.expand_dims(x_img, axis=0)\n",
        "\n",
        "\t\t\t\ty_rpn_regr[:, y_rpn_regr.shape[1]//2:, :, :] *= C.std_scaling\n",
        "\n",
        "\t\t\t\tif backend == 'tf':\n",
        "\t\t\t\t\tx_img = np.transpose(x_img, (0, 2, 3, 1))\n",
        "\t\t\t\t\ty_rpn_cls = np.transpose(y_rpn_cls, (0, 2, 3, 1))\n",
        "\t\t\t\t\ty_rpn_regr = np.transpose(y_rpn_regr, (0, 2, 3, 1))\n",
        "\n",
        "\t\t\t\tyield np.copy(x_img), [np.copy(y_rpn_cls), np.copy(y_rpn_regr)], img_data_aug\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue"
      ],
      "metadata": {
        "id": "P-Q8YfnrTwaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import categorical_crossentropy\n",
        "from keras import backend as K\n",
        "\n",
        "if K.image_data_format() == 'tf':\n",
        "\timport tensorflow as tf\n",
        "\n",
        "lambda_rpn_regr = 1.0\n",
        "lambda_rpn_class = 1.0\n",
        "\n",
        "lambda_cls_regr = 1.0\n",
        "lambda_cls_class = 1.0\n",
        "\n",
        "epsilon = 1e-4\n",
        "\n",
        "\n",
        "def rpn_loss_regr(num_anchors):\n",
        "\tdef rpn_loss_regr_fixed_num(y_true, y_pred):\n",
        "\t\tif K.image_dim_ordering() == 'th':\n",
        "\t\t\tx = y_true[:, 4 * num_anchors:, :, :] - y_pred\n",
        "\t\t\tx_abs = K.abs(x)\n",
        "\t\t\tx_bool = K.less_equal(x_abs, 1.0)\n",
        "\t\t\treturn lambda_rpn_regr * K.sum(\n",
        "\t\t\t\ty_true[:, :4 * num_anchors, :, :] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :4 * num_anchors, :, :])\n",
        "\t\telse:\n",
        "\t\t\tx = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
        "\t\t\tx_abs = K.abs(x)\n",
        "\t\t\tx_bool = K.cast(K.less_equal(x_abs, 1.0), tf.float32)\n",
        "\n",
        "\t\t\treturn lambda_rpn_regr * K.sum(\n",
        "\t\t\t\ty_true[:, :, :, :4 * num_anchors] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors])\n",
        "\n",
        "\treturn rpn_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def rpn_loss_cls(num_anchors):\n",
        "\tdef rpn_loss_cls_fixed_num(y_true, y_pred):\n",
        "\t\tif K.image_dim_ordering() == 'tf':\n",
        "\t\t\treturn lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
        "\t\telse:\n",
        "\t\t\treturn lambda_rpn_class * K.sum(y_true[:, :num_anchors, :, :] * K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, num_anchors:, :, :])) / K.sum(epsilon + y_true[:, :num_anchors, :, :])\n",
        "\n",
        "\treturn rpn_loss_cls_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_regr(num_classes):\n",
        "\tdef class_loss_regr_fixed_num(y_true, y_pred):\n",
        "\t\tx = y_true[:, :, 4*num_classes:] - y_pred\n",
        "\t\tx_abs = K.abs(x)\n",
        "\t\tx_bool = K.cast(K.less_equal(x_abs, 1.0), 'float32')\n",
        "\t\treturn lambda_cls_regr * K.sum(y_true[:, :, :4*num_classes] * (x_bool * (0.5 * x * x) + (1 - x_bool) * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :4*num_classes])\n",
        "\treturn class_loss_regr_fixed_num\n",
        "\n",
        "\n",
        "def class_loss_cls(y_true, y_pred):\n",
        "\treturn lambda_cls_class * K.mean(categorical_crossentropy(y_true[0, :, :], y_pred[0, :, :]))"
      ],
      "metadata": {
        "id": "chcoFqUOUHWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import numpy as np\n",
        "def get_data(input_path):\n",
        "\tall_imgs = []\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = False\n",
        "\n",
        "\tdata_paths = [os.path.join(input_path,s) for s in ['VOC2007', 'VOC2012']]\n",
        "\t\n",
        "\n",
        "\tprint('Parsing annotation files')\n",
        "\n",
        "\tfor data_path in data_paths:\n",
        "\n",
        "\t\tannot_path = os.path.join(data_path, 'Annotations')\n",
        "\t\timgs_path = os.path.join(data_path, 'JPEGImages')\n",
        "\t\timgsets_path_trainval = os.path.join(data_path, 'ImageSets','Main','trainval.txt')\n",
        "\t\timgsets_path_test = os.path.join(data_path, 'ImageSets','Main','test.txt')\n",
        "\n",
        "\t\ttrainval_files = []\n",
        "\t\ttest_files = []\n",
        "\t\ttry:\n",
        "\t\t\twith open(imgsets_path_trainval) as f:\n",
        "\t\t\t\tfor line in f:\n",
        "\t\t\t\t\ttrainval_files.append(line.strip() + '.jpg')\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint(e)\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\twith open(imgsets_path_test) as f:\n",
        "\t\t\t\tfor line in f:\n",
        "\t\t\t\t\ttest_files.append(line.strip() + '.jpg')\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tif data_path[-7:] == 'VOC2012':\n",
        "\t\t\t\t# this is expected, most pascal voc distibutions dont have the test.txt file\n",
        "\t\t\t\tpass\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\n",
        "\t\tannots = [os.path.join(annot_path, s) for s in os.listdir(annot_path)]\n",
        "\t\tidx = 0\n",
        "\t\tfor annot in annots:\n",
        "\t\t\ttry:\n",
        "\t\t\t\tidx += 1\n",
        "\n",
        "\t\t\t\tet = ET.parse(annot)\n",
        "\t\t\t\telement = et.getroot()\n",
        "\n",
        "\t\t\t\telement_objs = element.findall('object')\n",
        "\t\t\t\telement_filename = element.find('filename').text\n",
        "\t\t\t\telement_width = int(element.find('size').find('width').text)\n",
        "\t\t\t\telement_height = int(element.find('size').find('height').text)\n",
        "\n",
        "\t\t\t\tif len(element_objs) > 0:\n",
        "\t\t\t\t\tannotation_data = {'filepath': os.path.join(imgs_path, element_filename), 'width': element_width,\n",
        "\t\t\t\t\t\t\t\t\t   'height': element_height, 'bboxes': []}\n",
        "\n",
        "\t\t\t\t\tif element_filename in trainval_files:\n",
        "\t\t\t\t\t\tannotation_data['imageset'] = 'trainval'\n",
        "\t\t\t\t\telif element_filename in test_files:\n",
        "\t\t\t\t\t\tannotation_data['imageset'] = 'test'\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tannotation_data['imageset'] = 'trainval'\n",
        "\n",
        "\t\t\t\tfor element_obj in element_objs:\n",
        "\t\t\t\t\tclass_name = element_obj.find('name').text\n",
        "\t\t\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\t\t\telse:\n",
        "\t\t\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\t\t\tobj_bbox = element_obj.find('bndbox')\n",
        "\t\t\t\t\tx1 = int(round(float(obj_bbox.find('xmin').text)))\n",
        "\t\t\t\t\ty1 = int(round(float(obj_bbox.find('ymin').text)))\n",
        "\t\t\t\t\tx2 = int(round(float(obj_bbox.find('xmax').text)))\n",
        "\t\t\t\t\ty2 = int(round(float(obj_bbox.find('ymax').text)))\n",
        "\t\t\t\t\tdifficulty = int(element_obj.find('difficult').text) == 1\n",
        "\t\t\t\t\tannotation_data['bboxes'].append(\n",
        "\t\t\t\t\t\t{'class': class_name, 'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'difficult': difficulty})\n",
        "\t\t\t\tall_imgs.append(annotation_data)\n",
        "\n",
        "\t\t\t\tif visualise:\n",
        "\t\t\t\t\timg = cv2.imread(annotation_data['filepath'])\n",
        "\t\t\t\t\tfor bbox in annotation_data['bboxes']:\n",
        "\t\t\t\t\t\tcv2.rectangle(img, (bbox['x1'], bbox['y1']), (bbox[\n",
        "\t\t\t\t\t\t\t\t\t  'x2'], bbox['y2']), (0, 0, 255))\n",
        "\t\t\t\t\tcv2.imshow('img', img)\n",
        "\t\t\t\t\tcv2.waitKey(0)\n",
        "\n",
        "\t\t\texcept Exception as e:\n",
        "\t\t\t\tprint(e)\n",
        "\t\t\t\tcontinue\n",
        "\treturn all_imgs, classes_count, class_mapping"
      ],
      "metadata": {
        "id": "TdBozCl_V6eR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "'''ResNet50 model for Keras.\n",
        "# Reference:\n",
        "- [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)\n",
        "Adapted from code contributed by BigMoyan.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "from keras.layers import Input, Add, Dense, Activation, Flatten, Convolution2D, MaxPooling2D, ZeroPadding2D, \\\n",
        "    AveragePooling2D, TimeDistributed\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "def get_weight_path():\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        return 'resnet50_weights_th_dim_ordering_th_kernels_notop.h5'\n",
        "    else:\n",
        "        return 'resnet50_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "\n",
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        # zero_pad\n",
        "        input_length += 6\n",
        "        # apply 4 strided convolutions\n",
        "        filter_sizes = [7, 3, 1, 1]\n",
        "        stride = 2\n",
        "        for filter_size in filter_sizes:\n",
        "            input_length = (input_length - filter_size + stride) // stride\n",
        "        return input_length\n",
        "\n",
        "    return get_output_length(width), get_output_length(height) \n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    \n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, (1, 1), name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def identity_block_td(input_tensor, kernel_size, filters, stage, block, trainable=True):\n",
        "\n",
        "    # identity block time distributed\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2a')(input_tensor)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), trainable=trainable, kernel_initializer='normal',padding='same'), name=conv_name_base + '2b')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2c')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
        "\n",
        "    x = Add()([x, input_tensor])\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2), trainable=True):\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = Convolution2D(nb_filter1, (1, 1), strides=strides, name=conv_name_base + '2a', trainable=trainable)(input_tensor)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', name=conv_name_base + '2b', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Convolution2D(nb_filter3, (1, 1), name=conv_name_base + '2c', trainable=trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = Convolution2D(nb_filter3, (1, 1), strides=strides, name=conv_name_base + '1', trainable=trainable)(input_tensor)\n",
        "    shortcut = FixedBatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def conv_block_td(input_tensor, kernel_size, filters, stage, block, input_shape, strides=(2, 2), trainable=True):\n",
        "\n",
        "    # conv block time distributed\n",
        "\n",
        "    nb_filter1, nb_filter2, nb_filter3 = filters\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter1, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), input_shape=input_shape, name=conv_name_base + '2a')(input_tensor)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2a')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter2, (kernel_size, kernel_size), padding='same', trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '2b')(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2b')(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = TimeDistributed(Convolution2D(nb_filter3, (1, 1), kernel_initializer='normal'), name=conv_name_base + '2c', trainable=trainable)(x)\n",
        "    x = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '2c')(x)\n",
        "\n",
        "    shortcut = TimeDistributed(Convolution2D(nb_filter3, (1, 1), strides=strides, trainable=trainable, kernel_initializer='normal'), name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = TimeDistributed(FixedBatchNormalization(axis=bn_axis), name=bn_name_base + '1')(shortcut)\n",
        "\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "    # Determine proper input shape\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        input_shape = (3, None, None)\n",
        "    else:\n",
        "        input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    x = ZeroPadding2D((3, 3))(img_input)\n",
        "\n",
        "    x = Convolution2D(64, (7, 7), strides=(2, 2), name='conv1', trainable = trainable)(x)\n",
        "    x = FixedBatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1), trainable = trainable)\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b', trainable = trainable)\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c', trainable = trainable)\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a', trainable = trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b', trainable = trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c', trainable = trainable)\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d', trainable = trainable)\n",
        "\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a', trainable = trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b', trainable = trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c', trainable = trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d', trainable = trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e', trainable = trainable)\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f', trainable = trainable)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def classifier_layers(x, input_shape, trainable=False):\n",
        "\n",
        "    # compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
        "    # (hence a smaller stride in the region that follows the ROI pool)\n",
        "    if K.backend() == 'tensorflow':\n",
        "        x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a', input_shape=input_shape, strides=(2, 2), trainable=trainable)\n",
        "    elif K.backend() == 'theano':\n",
        "        x = conv_block_td(x, 3, [512, 512, 2048], stage=5, block='a', input_shape=input_shape, strides=(1, 1), trainable=trainable)\n",
        "\n",
        "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='b', trainable=trainable)\n",
        "    x = identity_block_td(x, 3, [512, 512, 2048], stage=5, block='c', trainable=trainable)\n",
        "    x = TimeDistributed(AveragePooling2D((7, 7)), name='avg_pool')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "def rpn(base_layers,num_anchors):\n",
        "\n",
        "    x = Convolution2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Convolution2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Convolution2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]\n",
        "\n",
        "def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
        "\n",
        "    # compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
        "\n",
        "    if K.backend() == 'tensorflow':\n",
        "        pooling_regions = 14\n",
        "        input_shape = (num_rois,14,14,1024)\n",
        "    elif K.backend() == 'theano':\n",
        "        pooling_regions = 7\n",
        "        input_shape = (num_rois,1024,7,7)\n",
        "\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "    out = classifier_layers(out_roi_pool, input_shape=input_shape, trainable=True)\n",
        "\n",
        "    out = TimeDistributed(Flatten())(out)\n",
        "\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # note: no regression target for bg class\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "    return [out_class, out_regr]"
      ],
      "metadata": {
        "id": "WLfNqNtnWJne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pdb\n",
        "import math\n",
        "import copy\n",
        "\n",
        "\n",
        "def calc_iou(R, img_data, C, class_mapping):\n",
        "\n",
        "\tbboxes = img_data['bboxes']\n",
        "\t(width, height) = (img_data['width'], img_data['height'])\n",
        "\t# get image dimensions for resizing\n",
        "\t(resized_width, resized_height) = data_generators.get_new_img_size(width, height, C.im_size)\n",
        "\n",
        "\tgta = np.zeros((len(bboxes), 4))\n",
        "\n",
        "\tfor bbox_num, bbox in enumerate(bboxes):\n",
        "\t\t# get the GT box coordinates, and resize to account for image resizing\n",
        "\t\tgta[bbox_num, 0] = int(round(bbox['x1'] * (resized_width / float(width))/C.rpn_stride))\n",
        "\t\tgta[bbox_num, 1] = int(round(bbox['x2'] * (resized_width / float(width))/C.rpn_stride))\n",
        "\t\tgta[bbox_num, 2] = int(round(bbox['y1'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\t\tgta[bbox_num, 3] = int(round(bbox['y2'] * (resized_height / float(height))/C.rpn_stride))\n",
        "\n",
        "\tx_roi = []\n",
        "\ty_class_num = []\n",
        "\ty_class_regr_coords = []\n",
        "\ty_class_regr_label = []\n",
        "\tIoUs = [] # for debugging only\n",
        "\n",
        "\tfor ix in range(R.shape[0]):\n",
        "\t\t(x1, y1, x2, y2) = R[ix, :]\n",
        "\t\tx1 = int(round(x1))\n",
        "\t\ty1 = int(round(y1))\n",
        "\t\tx2 = int(round(x2))\n",
        "\t\ty2 = int(round(y2))\n",
        "\n",
        "\t\tbest_iou = 0.0\n",
        "\t\tbest_bbox = -1\n",
        "\t\tfor bbox_num in range(len(bboxes)):\n",
        "\t\t\tcurr_iou = data_generators.iou([gta[bbox_num, 0], gta[bbox_num, 2], gta[bbox_num, 1], gta[bbox_num, 3]], [x1, y1, x2, y2])\n",
        "\t\t\tif curr_iou > best_iou:\n",
        "\t\t\t\tbest_iou = curr_iou\n",
        "\t\t\t\tbest_bbox = bbox_num\n",
        "\n",
        "\t\tif best_iou < C.classifier_min_overlap:\n",
        "\t\t\t\tcontinue\n",
        "\t\telse:\n",
        "\t\t\tw = x2 - x1\n",
        "\t\t\th = y2 - y1\n",
        "\t\t\tx_roi.append([x1, y1, w, h])\n",
        "\t\t\tIoUs.append(best_iou)\n",
        "\n",
        "\t\t\tif C.classifier_min_overlap <= best_iou < C.classifier_max_overlap:\n",
        "\t\t\t\t# hard negative example\n",
        "\t\t\t\tcls_name = 'bg'\n",
        "\t\t\telif C.classifier_max_overlap <= best_iou:\n",
        "\t\t\t\tcls_name = bboxes[best_bbox]['class']\n",
        "\t\t\t\tcxg = (gta[best_bbox, 0] + gta[best_bbox, 1]) / 2.0\n",
        "\t\t\t\tcyg = (gta[best_bbox, 2] + gta[best_bbox, 3]) / 2.0\n",
        "\n",
        "\t\t\t\tcx = x1 + w / 2.0\n",
        "\t\t\t\tcy = y1 + h / 2.0\n",
        "\n",
        "\t\t\t\ttx = (cxg - cx) / float(w)\n",
        "\t\t\t\tty = (cyg - cy) / float(h)\n",
        "\t\t\t\ttw = np.log((gta[best_bbox, 1] - gta[best_bbox, 0]) / float(w))\n",
        "\t\t\t\tth = np.log((gta[best_bbox, 3] - gta[best_bbox, 2]) / float(h))\n",
        "\t\t\telse:\n",
        "\t\t\t\tprint('roi = {}'.format(best_iou))\n",
        "\t\t\t\traise RuntimeError\n",
        "\n",
        "\t\tclass_num = class_mapping[cls_name]\n",
        "\t\tclass_label = len(class_mapping) * [0]\n",
        "\t\tclass_label[class_num] = 1\n",
        "\t\ty_class_num.append(copy.deepcopy(class_label))\n",
        "\t\tcoords = [0] * 4 * (len(class_mapping) - 1)\n",
        "\t\tlabels = [0] * 4 * (len(class_mapping) - 1)\n",
        "\t\tif cls_name != 'bg':\n",
        "\t\t\tlabel_pos = 4 * class_num\n",
        "\t\t\tsx, sy, sw, sh = C.classifier_regr_std\n",
        "\t\t\tcoords[label_pos:4+label_pos] = [sx*tx, sy*ty, sw*tw, sh*th]\n",
        "\t\t\tlabels[label_pos:4+label_pos] = [1, 1, 1, 1]\n",
        "\t\t\ty_class_regr_coords.append(copy.deepcopy(coords))\n",
        "\t\t\ty_class_regr_label.append(copy.deepcopy(labels))\n",
        "\t\telse:\n",
        "\t\t\ty_class_regr_coords.append(copy.deepcopy(coords))\n",
        "\t\t\ty_class_regr_label.append(copy.deepcopy(labels))\n",
        "\n",
        "\tif len(x_roi) == 0:\n",
        "\t\treturn None, None, None, None\n",
        "\n",
        "\tX = np.array(x_roi)\n",
        "\tY1 = np.array(y_class_num)\n",
        "\tY2 = np.concatenate([np.array(y_class_regr_label),np.array(y_class_regr_coords)],axis=1)\n",
        "\n",
        "\treturn np.expand_dims(X, axis=0), np.expand_dims(Y1, axis=0), np.expand_dims(Y2, axis=0), IoUs\n",
        "\n",
        "def apply_regr(x, y, w, h, tx, ty, tw, th):\n",
        "\ttry:\n",
        "\t\tcx = x + w/2.\n",
        "\t\tcy = y + h/2.\n",
        "\t\tcx1 = tx * w + cx\n",
        "\t\tcy1 = ty * h + cy\n",
        "\t\tw1 = math.exp(tw) * w\n",
        "\t\th1 = math.exp(th) * h\n",
        "\t\tx1 = cx1 - w1/2.\n",
        "\t\ty1 = cy1 - h1/2.\n",
        "\t\tx1 = int(round(x1))\n",
        "\t\ty1 = int(round(y1))\n",
        "\t\tw1 = int(round(w1))\n",
        "\t\th1 = int(round(h1))\n",
        "\n",
        "\t\treturn x1, y1, w1, h1\n",
        "\n",
        "\texcept ValueError:\n",
        "\t\treturn x, y, w, h\n",
        "\texcept OverflowError:\n",
        "\t\treturn x, y, w, h\n",
        "\texcept Exception as e:\n",
        "\t\tprint(e)\n",
        "\t\treturn x, y, w, h\n",
        "\n",
        "def apply_regr_np(X, T):\n",
        "\ttry:\n",
        "\t\tx = X[0, :, :]\n",
        "\t\ty = X[1, :, :]\n",
        "\t\tw = X[2, :, :]\n",
        "\t\th = X[3, :, :]\n",
        "\n",
        "\t\ttx = T[0, :, :]\n",
        "\t\tty = T[1, :, :]\n",
        "\t\ttw = T[2, :, :]\n",
        "\t\tth = T[3, :, :]\n",
        "\n",
        "\t\tcx = x + w/2.\n",
        "\t\tcy = y + h/2.\n",
        "\t\tcx1 = tx * w + cx\n",
        "\t\tcy1 = ty * h + cy\n",
        "\n",
        "\t\tw1 = np.exp(tw.astype(np.float64)) * w\n",
        "\t\th1 = np.exp(th.astype(np.float64)) * h\n",
        "\t\tx1 = cx1 - w1/2.\n",
        "\t\ty1 = cy1 - h1/2.\n",
        "\n",
        "\t\tx1 = np.round(x1)\n",
        "\t\ty1 = np.round(y1)\n",
        "\t\tw1 = np.round(w1)\n",
        "\t\th1 = np.round(h1)\n",
        "\t\treturn np.stack([x1, y1, w1, h1])\n",
        "\texcept Exception as e:\n",
        "\t\tprint(e)\n",
        "\t\treturn X\n",
        "\n",
        "def non_max_suppression_fast(boxes, probs, overlap_thresh=0.9, max_boxes=300):\n",
        "\t# code used from here: http://www.pyimagesearch.com/2015/02/16/faster-non-maximum-suppression-python/\n",
        "\t# if there are no boxes, return an empty list\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        "\n",
        "\t# grab the coordinates of the bounding boxes\n",
        "\tx1 = boxes[:, 0]\n",
        "\ty1 = boxes[:, 1]\n",
        "\tx2 = boxes[:, 2]\n",
        "\ty2 = boxes[:, 3]\n",
        "\n",
        "\tnp.testing.assert_array_less(x1, x2)\n",
        "\tnp.testing.assert_array_less(y1, y2)\n",
        "\n",
        "\t# if the bounding boxes integers, convert them to floats --\n",
        "\t# this is important since we'll be doing a bunch of divisions\n",
        "\tif boxes.dtype.kind == \"i\":\n",
        "\t\tboxes = boxes.astype(\"float\")\n",
        "\n",
        "\t# initialize the list of picked indexes\t\n",
        "\tpick = []\n",
        "\n",
        "\t# calculate the areas\n",
        "\tarea = (x2 - x1) * (y2 - y1)\n",
        "\n",
        "\t# sort the bounding boxes \n",
        "\tidxs = np.argsort(probs)\n",
        "\n",
        "\t# keep looping while some indexes still remain in the indexes\n",
        "\t# list\n",
        "\twhile len(idxs) > 0:\n",
        "\t\t# grab the last index in the indexes list and add the\n",
        "\t\t# index value to the list of picked indexes\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        "\n",
        "\t\t# find the intersection\n",
        "\n",
        "\t\txx1_int = np.maximum(x1[i], x1[idxs[:last]])\n",
        "\t\tyy1_int = np.maximum(y1[i], y1[idxs[:last]])\n",
        "\t\txx2_int = np.minimum(x2[i], x2[idxs[:last]])\n",
        "\t\tyy2_int = np.minimum(y2[i], y2[idxs[:last]])\n",
        "\n",
        "\t\tww_int = np.maximum(0, xx2_int - xx1_int)\n",
        "\t\thh_int = np.maximum(0, yy2_int - yy1_int)\n",
        "\n",
        "\t\tarea_int = ww_int * hh_int\n",
        "\n",
        "\t\t# find the union\n",
        "\t\tarea_union = area[i] + area[idxs[:last]] - area_int\n",
        "\n",
        "\t\t# compute the ratio of overlap\n",
        "\t\toverlap = area_int/(area_union + 1e-6)\n",
        "\n",
        "\t\t# delete all indexes from the index list that have\n",
        "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
        "\t\t\tnp.where(overlap > overlap_thresh)[0])))\n",
        "\n",
        "\t\tif len(pick) >= max_boxes:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t# return only the bounding boxes that were picked using the integer data type\n",
        "\tboxes = boxes[pick].astype(\"int\")\n",
        "\tprobs = probs[pick]\n",
        "\treturn boxes, probs\n",
        "\n",
        "import time\n",
        "def rpn_to_roi(rpn_layer, regr_layer, C, dim_ordering, use_regr=True, max_boxes=300,overlap_thresh=0.9):\n",
        "\n",
        "\tregr_layer = regr_layer / C.std_scaling\n",
        "\n",
        "\tanchor_sizes = C.anchor_box_scales\n",
        "\tanchor_ratios = C.anchor_box_ratios\n",
        "\n",
        "\tassert rpn_layer.shape[0] == 1\n",
        "\n",
        "\tif dim_ordering == 'th':\n",
        "\t\t(rows,cols) = rpn_layer.shape[2:]\n",
        "\n",
        "\telif dim_ordering == 'tf':\n",
        "\t\t(rows, cols) = rpn_layer.shape[1:3]\n",
        "\n",
        "\tcurr_layer = 0\n",
        "\tif dim_ordering == 'tf':\n",
        "\t\tA = np.zeros((4, rpn_layer.shape[1], rpn_layer.shape[2], rpn_layer.shape[3]))\n",
        "\telif dim_ordering == 'th':\n",
        "\t\tA = np.zeros((4, rpn_layer.shape[2], rpn_layer.shape[3], rpn_layer.shape[1]))\n",
        "\n",
        "\tfor anchor_size in anchor_sizes:\n",
        "\t\tfor anchor_ratio in anchor_ratios:\n",
        "\n",
        "\t\t\tanchor_x = (anchor_size * anchor_ratio[0])/C.rpn_stride\n",
        "\t\t\tanchor_y = (anchor_size * anchor_ratio[1])/C.rpn_stride\n",
        "\t\t\tif dim_ordering == 'th':\n",
        "\t\t\t\tregr = regr_layer[0, 4 * curr_layer:4 * curr_layer + 4, :, :]\n",
        "\t\t\telse:\n",
        "\t\t\t\tregr = regr_layer[0, :, :, 4 * curr_layer:4 * curr_layer + 4]\n",
        "\t\t\t\tregr = np.transpose(regr, (2, 0, 1))\n",
        "\n",
        "\t\t\tX, Y = np.meshgrid(np.arange(cols),np. arange(rows))\n",
        "\n",
        "\t\t\tA[0, :, :, curr_layer] = X - anchor_x/2\n",
        "\t\t\tA[1, :, :, curr_layer] = Y - anchor_y/2\n",
        "\t\t\tA[2, :, :, curr_layer] = anchor_x\n",
        "\t\t\tA[3, :, :, curr_layer] = anchor_y\n",
        "\n",
        "\t\t\tif use_regr:\n",
        "\t\t\t\tA[:, :, :, curr_layer] = apply_regr_np(A[:, :, :, curr_layer], regr)\n",
        "\n",
        "\t\t\tA[2, :, :, curr_layer] = np.maximum(1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.maximum(1, A[3, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] += A[0, :, :, curr_layer]\n",
        "\t\t\tA[3, :, :, curr_layer] += A[1, :, :, curr_layer]\n",
        "\n",
        "\t\t\tA[0, :, :, curr_layer] = np.maximum(0, A[0, :, :, curr_layer])\n",
        "\t\t\tA[1, :, :, curr_layer] = np.maximum(0, A[1, :, :, curr_layer])\n",
        "\t\t\tA[2, :, :, curr_layer] = np.minimum(cols-1, A[2, :, :, curr_layer])\n",
        "\t\t\tA[3, :, :, curr_layer] = np.minimum(rows-1, A[3, :, :, curr_layer])\n",
        "\n",
        "\t\t\tcurr_layer += 1\n",
        "\n",
        "\tall_boxes = np.reshape(A.transpose((0, 3, 1,2)), (4, -1)).transpose((1, 0))\n",
        "\tall_probs = rpn_layer.transpose((0, 3, 1, 2)).reshape((-1))\n",
        "\n",
        "\tx1 = all_boxes[:, 0]\n",
        "\ty1 = all_boxes[:, 1]\n",
        "\tx2 = all_boxes[:, 2]\n",
        "\ty2 = all_boxes[:, 3]\n",
        "\n",
        "\tidxs = np.where((x1 - x2 >= 0) | (y1 - y2 >= 0))\n",
        "\n",
        "\tall_boxes = np.delete(all_boxes, idxs, 0)\n",
        "\tall_probs = np.delete(all_probs, idxs, 0)\n",
        "\n",
        "\tresult = non_max_suppression_fast(all_boxes, all_probs, overlap_thresh=overlap_thresh, max_boxes=max_boxes)[0]\n",
        "\n",
        "\treturn result"
      ],
      "metadata": {
        "id": "zCnl9GjjWeNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def get_data(input_path):\n",
        "\tfound_bg = False\n",
        "\tall_imgs = {}\n",
        "\n",
        "\tclasses_count = {}\n",
        "\n",
        "\tclass_mapping = {}\n",
        "\n",
        "\tvisualise = True\n",
        "\t\n",
        "\twith open(input_path,'r') as f:\n",
        "\n",
        "\t\tprint('Parsing annotation files')\n",
        "\n",
        "\t\tfor line in f:\n",
        "\t\t\tline_split = line.strip().split(',')\n",
        "\t\t\t(filename,x1,y1,x2,y2,class_name) = line_split\n",
        "\n",
        "\t\t\tif class_name not in classes_count:\n",
        "\t\t\t\tclasses_count[class_name] = 1\n",
        "\t\t\telse:\n",
        "\t\t\t\tclasses_count[class_name] += 1\n",
        "\n",
        "\t\t\tif class_name not in class_mapping:\n",
        "\t\t\t\tif class_name == 'bg' and found_bg == False:\n",
        "\t\t\t\t\tprint('Found class name with special name bg. Will be treated as a background region (this is usually for hard negative mining).')\n",
        "\t\t\t\t\tfound_bg = True\n",
        "\t\t\t\tclass_mapping[class_name] = len(class_mapping)\n",
        "\n",
        "\t\t\tif filename not in all_imgs:\n",
        "\t\t\t\tall_imgs[filename] = {}\n",
        "\t\t\t\t\n",
        "\t\t\t\timg = cv2.imread(filename)\n",
        "\t\t\t\t(rows,cols) = img.shape[:2]\n",
        "\t\t\t\tall_imgs[filename]['filepath'] = filename\n",
        "\t\t\t\tall_imgs[filename]['width'] = cols\n",
        "\t\t\t\tall_imgs[filename]['height'] = rows\n",
        "\t\t\t\tall_imgs[filename]['bboxes'] = []\n",
        "\t\t\t\tif np.random.randint(0,6) > 0:\n",
        "\t\t\t\t\tall_imgs[filename]['imageset'] = 'trainval'\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tall_imgs[filename]['imageset'] = 'test'\n",
        "\n",
        "\t\t\tall_imgs[filename]['bboxes'].append({'class': class_name, 'x1': int(x1), 'x2': int(x2), 'y1': int(y1), 'y2': int(y2)})\n",
        "\n",
        "\n",
        "\t\tall_data = []\n",
        "\t\tfor key in all_imgs:\n",
        "\t\t\tall_data.append(all_imgs[key])\n",
        "\t\t\n",
        "\t\t# make sure the bg class is last in the list\n",
        "\t\tif found_bg:\n",
        "\t\t\tif class_mapping['bg'] != len(class_mapping) - 1:\n",
        "\t\t\t\tkey_to_switch = [key for key in class_mapping.keys() if class_mapping[key] == len(class_mapping)-1][0]\n",
        "\t\t\t\tval_to_switch = class_mapping['bg']\n",
        "\t\t\t\tclass_mapping['bg'] = len(class_mapping) - 1\n",
        "\t\t\t\tclass_mapping[key_to_switch] = val_to_switch\n",
        "\t\t\n",
        "\t\treturn all_data, classes_count, class_mapping"
      ],
      "metadata": {
        "id": "YtiEWPBnWkwu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"VGG16 model for Keras.\n",
        "# Reference\n",
        "- [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)\n",
        "\"\"\"\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "\n",
        "import warnings\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout\n",
        "from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "from keras.utils.layer_utils import get_source_inputs\n",
        "from keras.utils import layer_utils\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras import backend as K\n",
        "\n",
        "def get_weight_path():\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        print('pretrained weights not available for VGG with theano backend')\n",
        "        return\n",
        "    else:\n",
        "        return 'vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
        "\n",
        "\n",
        "def get_img_output_length(width, height):\n",
        "    def get_output_length(input_length):\n",
        "        return input_length//16\n",
        "\n",
        "    return get_output_length(width), get_output_length(height)    \n",
        "\n",
        "def nn_base(input_tensor=None, trainable=False):\n",
        "\n",
        "\n",
        "    # Determine proper input shape\n",
        "    if K.image_dim_ordering() == 'th':\n",
        "        input_shape = (3, None, None)\n",
        "    else:\n",
        "        input_shape = (None, None, 3)\n",
        "\n",
        "    if input_tensor is None:\n",
        "        img_input = Input(shape=input_shape)\n",
        "    else:\n",
        "        if not K.is_keras_tensor(input_tensor):\n",
        "            img_input = Input(tensor=input_tensor, shape=input_shape)\n",
        "        else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "    if K.image_dim_ordering() == 'tf':\n",
        "        bn_axis = 3\n",
        "    else:\n",
        "        bn_axis = 1\n",
        "\n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(img_input)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "    # x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def rpn(base_layers, num_anchors):\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv1')(base_layers)\n",
        "\n",
        "    x_class = Conv2D(num_anchors, (1, 1), activation='sigmoid', kernel_initializer='uniform', name='rpn_out_class')(x)\n",
        "    x_regr = Conv2D(num_anchors * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_out_regress')(x)\n",
        "\n",
        "    return [x_class, x_regr, base_layers]\n",
        "\n",
        "\n",
        "def classifier(base_layers, input_rois, num_rois, nb_classes = 21, trainable=False):\n",
        "\n",
        "    # compile times on theano tend to be very high, so we use smaller ROI pooling regions to workaround\n",
        "\n",
        "    if K.backend() == 'tensorflow':\n",
        "        pooling_regions = 7\n",
        "        input_shape = (num_rois,7,7,512)\n",
        "    elif K.backend() == 'theano':\n",
        "        pooling_regions = 7\n",
        "        input_shape = (num_rois,512,7,7)\n",
        "\n",
        "    out_roi_pool = RoiPoolingConv(pooling_regions, num_rois)([base_layers, input_rois])\n",
        "\n",
        "    out = TimeDistributed(Flatten(name='flatten'))(out_roi_pool)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc1'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "    out = TimeDistributed(Dense(4096, activation='relu', name='fc2'))(out)\n",
        "    out = TimeDistributed(Dropout(0.5))(out)\n",
        "\n",
        "    out_class = TimeDistributed(Dense(nb_classes, activation='softmax', kernel_initializer='zero'), name='dense_class_{}'.format(nb_classes))(out)\n",
        "    # note: no regression target for bg class\n",
        "    out_regr = TimeDistributed(Dense(4 * (nb_classes-1), activation='linear', kernel_initializer='zero'), name='dense_regress_{}'.format(nb_classes))(out)\n",
        "\n",
        "    return [out_class, out_regr]"
      ],
      "metadata": {
        "id": "lfCQlzxvW2BZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Annotation"
      ],
      "metadata": {
        "id": "xjjj7d20XnjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "\n",
        "#Function to create a new csv file with the images,bbox coordinate and total bboxes in that image\n",
        "def create_new_csv(filename):\n",
        "    df= pd.read_csv(filename)\n",
        "    \n",
        "    #Creating a dictionary out of the image as key and the total bboxes in it as value\n",
        "    unordered_dictionary=dict(df['Name'].value_counts())\n",
        "    #print(unordered_dictionary)\n",
        "    \n",
        "    #Creating a ordered dicctionary using the name of the image as the key\n",
        "    dictionary=OrderedDict(sorted(unordered_dictionary.items()), key=lambda x:x[0])\n",
        "    dictionary.popitem()\n",
        "    \n",
        "    #print(dictionary)\n",
        "    \n",
        "    #Appending head count to a list\n",
        "    count=list()\n",
        "    for k,v in dictionary.items():\n",
        "        for i in range(v):\n",
        "            count.append(v)\n",
        "        \n",
        "    df['headcount']=count   \n",
        "    \n",
        "    #Creating a new csv file with the images,bboxes and labels\n",
        "    df.to_csv('image_bbox_label.csv', index=False)\n",
        "    \n",
        "    \n",
        "create_new_csv(r'/content/sample_data/bbox_train.csv')   \n",
        "\n",
        "df= pd.read_csv('/content/sample_data/image_bbox_label.csv')\n",
        "\n",
        "data = pd.DataFrame()\n",
        "data['format'] = df['Name']\n",
        "\n",
        "df['xmin']=df['xmin'].astype(str)\n",
        "df['ymin']=df['ymin'].astype(str)\n",
        "df['xmax']=df['xmax'].astype(str)\n",
        "df['ymax']=df['ymax'].astype(str)\n",
        "df['headcount']=df['headcount'].astype(str)\n",
        "print(df.dtypes)\n",
        "\n",
        "# as the images are in train_images folder, add train_images before the image name\n",
        "for i in range(data.shape[0]):\n",
        "    data['format'][i] = r'image_data/{}'.format(data['format'][i])\n",
        "\n",
        "# add xmin, ymin, xmax, ymax and class as per the format required\n",
        "for i in range(data.shape[0]):\n",
        "    data['format'][i] = data['format'][i] + ',' + df['xmin'][i] + ',' + df['ymin'][i] + ',' + df['xmax'][i] + ',' + df['ymax'][i] + ',' + df['headcount'][i]\n",
        "\n",
        "data.to_csv('annotate.txt', header=None, index=None, sep=' ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAEq4lojXsnP",
        "outputId": "69497a69-9154-4c43-90d7-874304897bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name         object\n",
            "width         int64\n",
            "height        int64\n",
            "xmin         object\n",
            "ymin         object\n",
            "xmax         object\n",
            "ymax         object\n",
            "headcount    object\n",
            "dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "from optparse import OptionParser\n",
        "import time\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from sklearn.metrics import average_precision_score\n",
        "\n",
        "def get_map(pred, gt, f):\n",
        "\tT = {}\n",
        "\tP = {}\n",
        "\tfx, fy = f\n",
        "\n",
        "\tfor bbox in gt:\n",
        "\t\tbbox['bbox_matched'] = False\n",
        "\n",
        "\tpred_probs = np.array([s['prob'] for s in pred])\n",
        "\tbox_idx_sorted_by_prob = np.argsort(pred_probs)[::-1]\n",
        "\n",
        "\tfor box_idx in box_idx_sorted_by_prob:\n",
        "\t\tpred_box = pred[box_idx]\n",
        "\t\tpred_class = pred_box['class']\n",
        "\t\tpred_x1 = pred_box['x1']\n",
        "\t\tpred_x2 = pred_box['x2']\n",
        "\t\tpred_y1 = pred_box['y1']\n",
        "\t\tpred_y2 = pred_box['y2']\n",
        "\t\tpred_prob = pred_box['prob']\n",
        "\t\tif pred_class not in P:\n",
        "\t\t\tP[pred_class] = []\n",
        "\t\t\tT[pred_class] = []\n",
        "\t\tP[pred_class].append(pred_prob)\n",
        "\t\tfound_match = False\n",
        "\n",
        "\t\tfor gt_box in gt:\n",
        "\t\t\tgt_class = gt_box['class']\n",
        "\t\t\tgt_x1 = gt_box['x1']/fx\n",
        "\t\t\tgt_x2 = gt_box['x2']/fx\n",
        "\t\t\tgt_y1 = gt_box['y1']/fy\n",
        "\t\t\tgt_y2 = gt_box['y2']/fy\n",
        "\t\t\tgt_seen = gt_box['bbox_matched']\n",
        "\t\t\tif gt_class != pred_class:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tif gt_seen:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tiou = data_generators.iou((pred_x1, pred_y1, pred_x2, pred_y2), (gt_x1, gt_y1, gt_x2, gt_y2))\n",
        "\t\t\tif iou >= 0.5:\n",
        "\t\t\t\tfound_match = True\n",
        "\t\t\t\tgt_box['bbox_matched'] = True\n",
        "\t\t\t\tbreak\n",
        "\t\t\telse:\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\tT[pred_class].append(int(found_match))\n",
        "\n",
        "\tfor gt_box in gt:\n",
        "\t\tif not gt_box['bbox_matched'] and not gt_box['difficult']:\n",
        "\t\t\tif gt_box['class'] not in P:\n",
        "\t\t\t\tP[gt_box['class']] = []\n",
        "\t\t\t\tT[gt_box['class']] = []\n",
        "\n",
        "\t\t\tT[gt_box['class']].append(1)\n",
        "\t\t\tP[gt_box['class']].append(0)\n",
        "\n",
        "\t#import pdb\n",
        "\t#pdb.set_trace()\n",
        "\treturn T, P\n",
        "\n",
        "sys.setrecursionlimit(40000)\n",
        "\n",
        "parser = OptionParser()\n",
        "\n",
        "parser.add_option('-f')\n",
        "parser.add_option(\"-p\", \"--path\", dest=\"test_path\", help=\"Path to test data.\")\n",
        "parser.add_option(\"-n\", \"--num_rois\", dest=\"num_rois\",\n",
        "\t\t\t\thelp=\"Number of ROIs per iteration. Higher means more memory use.\", default=32)\n",
        "parser.add_option(\"--config_filename\", dest=\"config_filename\", help=\n",
        "\t\t\t\t\"Location to read the metadata related to the training (generated when training).\",\n",
        "\t\t\t\tdefault=\"config.pickle\")\n",
        "parser.add_option(\"-o\", \"--parser\", dest=\"parser\", help=\"Parser to use. One of simple or pascal_voc\",\n",
        "\t\t\t\tdefault=\"pascal_voc\"),\n",
        "\n",
        "(options, args) = parser.parse_args()\n",
        "\n",
        "if not options.test_path:   # if filename is not given\n",
        "\tparser.error('Error: path to test data must be specified. Pass --path to command line')\n",
        "\n",
        "\n",
        "if options.parser == 'pascal_voc':\n",
        "\tfrom . import get_data\n",
        "elif options.parser == 'simple':\n",
        "\tfrom . import get_data\n",
        "else:\n",
        "\traise ValueError(\"Command line option parser must be one of 'pascal_voc' or 'simple'\")\n",
        "\n",
        "config_output_filename = options.config_filename\n",
        "\n",
        "with open(config_output_filename, 'r') as f_in:\n",
        "\tC = pickle.load(f_in)\n",
        "\n",
        "# turn off any data augmentation at test time\n",
        "C.use_horizontal_flips = False\n",
        "C.use_vertical_flips = False\n",
        "C.rot_90 = False\n",
        "\n",
        "img_path = options.test_path\n",
        "\n",
        "\n",
        "def format_img(img, C):\n",
        "\timg_min_side = float(C.im_size)\n",
        "\t(height,width,_) = img.shape\n",
        "\t\n",
        "\tif width <= height:\n",
        "\t\tf = img_min_side/width\n",
        "\t\tnew_height = int(f * height)\n",
        "\t\tnew_width = int(img_min_side)\n",
        "\telse:\n",
        "\t\tf = img_min_side/height\n",
        "\t\tnew_width = int(f * width)\n",
        "\t\tnew_height = int(img_min_side)\n",
        "\tfx = width/float(new_width)\n",
        "\tfy = height/float(new_height)\n",
        "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\timg = img[:, :, (2, 1, 0)]\n",
        "\timg = img.astype(np.float32)\n",
        "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
        "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
        "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
        "\timg /= C.img_scaling_factor\n",
        "\timg = np.transpose(img, (2, 0, 1))\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img, fx, fy\n",
        "\n",
        "\n",
        "class_mapping = C.class_mapping\n",
        "\n",
        "if 'bg' not in class_mapping:\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "class_mapping = {v: k for k, v in class_mapping.iteritems()}\n",
        "print(class_mapping)\n",
        "class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}\n",
        "C.num_rois = int(options.num_rois)\n",
        "\n",
        "if K.image_dim_ordering() == 'th':\n",
        "\tinput_shape_img = (3, None, None)\n",
        "\tinput_shape_features = (1024, None, None)\n",
        "else:\n",
        "\tinput_shape_img = (None, None, 3)\n",
        "\tinput_shape_features = (None, None, 1024)\n",
        "\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(C.num_rois, 4))\n",
        "feature_map_input = Input(shape=input_shape_features)\n",
        "\n",
        "# define the base network (resnet here, can be VGG, Inception, etc)\n",
        "shared_layers = nn_base(img_input, trainable=True)\n",
        "\n",
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn_layers = rpn(shared_layers, num_anchors)\n",
        "\n",
        "classifier = classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(class_mapping), trainable=True)\n",
        "\n",
        "model_rpn = Model(img_input, rpn_layers)\n",
        "model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "\n",
        "model_rpn.compile(optimizer='sgd', loss='mse')\n",
        "model_classifier.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "all_imgs, _, _ = get_data(options.test_path)\n",
        "test_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
        "\n",
        "\n",
        "T = {}\n",
        "P = {}\n",
        "for idx, img_data in enumerate(test_imgs):\n",
        "\tprint('{}/{}'.format(idx,len(test_imgs)))\n",
        "\tst = time.time()\n",
        "\tfilepath = img_data['filepath']\n",
        "\n",
        "\timg = cv2.imread(filepath)\n",
        "\n",
        "\tX, fx, fy = format_img(img, C)\n",
        "\n",
        "\tif K.image_dim_ordering() == 'tf':\n",
        "\t\tX = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "\t# get the feature maps and output from the RPN\n",
        "\t[Y1, Y2, F] = model_rpn.predict(X)\n",
        "\n",
        "\tR = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
        "\n",
        "\t# convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "\tR[:, 2] -= R[:, 0]\n",
        "\tR[:, 3] -= R[:, 1]\n",
        "\n",
        "\t# apply the spatial pyramid pooling to the proposed regions\n",
        "\tbboxes = {}\n",
        "\tprobs = {}\n",
        "\n",
        "\tfor jk in range(R.shape[0] // C.num_rois + 1):\n",
        "\t\tROIs = np.expand_dims(R[C.num_rois * jk:C.num_rois * (jk + 1), :], axis=0)\n",
        "\t\tif ROIs.shape[1] == 0:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tif jk == R.shape[0] // C.num_rois:\n",
        "\t\t\t# pad R\n",
        "\t\t\tcurr_shape = ROIs.shape\n",
        "\t\t\ttarget_shape = (curr_shape[0], C.num_rois, curr_shape[2])\n",
        "\t\t\tROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "\t\t\tROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "\t\t\tROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "\t\t\tROIs = ROIs_padded\n",
        "\n",
        "\t\t[P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n",
        "\n",
        "\t\tfor ii in range(P_cls.shape[1]):\n",
        "\n",
        "\t\t\tif np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tcls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "\t\t\tif cls_name not in bboxes:\n",
        "\t\t\t\tbboxes[cls_name] = []\n",
        "\t\t\t\tprobs[cls_name] = []\n",
        "\n",
        "\t\t\t(x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "\t\t\tcls_num = np.argmax(P_cls[0, ii, :])\n",
        "\t\t\ttry:\n",
        "\t\t\t\t(tx, ty, tw, th) = P_regr[0, ii, 4 * cls_num:4 * (cls_num + 1)]\n",
        "\t\t\t\ttx /= C.classifier_regr_std[0]\n",
        "\t\t\t\tty /= C.classifier_regr_std[1]\n",
        "\t\t\t\ttw /= C.classifier_regr_std[2]\n",
        "\t\t\t\tth /= C.classifier_regr_std[3]\n",
        "\t\t\t\tx, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "\t\t\texcept:\n",
        "\t\t\t\tpass\n",
        "\t\t\tbboxes[cls_name].append([16 * x, 16 * y, 16 * (x + w), 16 * (y + h)])\n",
        "\t\t\tprobs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "\tall_dets = []\n",
        "\n",
        "\tfor key in bboxes:\n",
        "\t\tbbox = np.array(bboxes[key])\n",
        "\n",
        "\t\tnew_boxes, new_probs = roi_helpers.non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
        "\t\tfor jk in range(new_boxes.shape[0]):\n",
        "\t\t\t(x1, y1, x2, y2) = new_boxes[jk, :]\n",
        "\t\t\tdet = {'x1': x1, 'x2': x2, 'y1': y1, 'y2': y2, 'class': key, 'prob': new_probs[jk]}\n",
        "\t\t\tall_dets.append(det)\n",
        "\n",
        "\n",
        "\tprint('Elapsed time = {}'.format(time.time() - st))\n",
        "\tt, p = get_map(all_dets, img_data['bboxes'], (fx, fy))\n",
        "\tfor key in t.keys():\n",
        "\t\tif key not in T:\n",
        "\t\t\tT[key] = []\n",
        "\t\t\tP[key] = []\n",
        "\t\tT[key].extend(t[key])\n",
        "\t\tP[key].extend(p[key])\n",
        "\tall_aps = []\n",
        "\tfor key in T.keys():\n",
        "\t\tap = average_precision_score(T[key], P[key])\n",
        "\t\tprint('{} AP: {}'.format(key, ap))\n",
        "\t\tall_aps.append(ap)\n",
        "\tprint('mAP = {}'.format(np.mean(np.array(all_aps))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "kNHL2UJ9XxBu",
        "outputId": "b7416309-02cc-439f-866a-c13fdfe41e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Usage: ipykernel_launcher.py [options]\n",
            "\n",
            "ipykernel_launcher.py: error: Error: path to test data must be specified. Pass --path to command line\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle\n",
        "from optparse import OptionParser\n",
        "import time\n",
        "from keras_frcnn import config\n",
        "from keras import backend as K\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras_frcnn import roi_helpers\n",
        "\n",
        "sys.setrecursionlimit(40000)\n",
        "\n",
        "parser = OptionParser()\n",
        "\n",
        "parser.add_option(\"-p\", \"--path\", dest=\"test_path\", help=\"Path to test data.\")\n",
        "parser.add_option(\"-n\", \"--num_rois\", type=\"int\", dest=\"num_rois\",\n",
        "\t\t\t\thelp=\"Number of ROIs per iteration. Higher means more memory use.\", default=32)\n",
        "parser.add_option(\"--config_filename\", dest=\"config_filename\", help=\n",
        "\t\t\t\t\"Location to read the metadata related to the training (generated when training).\",\n",
        "\t\t\t\tdefault=\"config.pickle\")\n",
        "parser.add_option(\"--network\", dest=\"network\", help=\"Base network to use. Supports vgg or resnet50.\", default='resnet50')\n",
        "\n",
        "(options, args) = parser.parse_args()\n",
        "\n",
        "if not options.test_path:   # if filename is not given\n",
        "\tparser.error('Error: path to test data must be specified. Pass --path to command line')\n",
        "\n",
        "\n",
        "config_output_filename = options.config_filename\n",
        "\n",
        "with open(config_output_filename, 'rb') as f_in:\n",
        "\tC = pickle.load(f_in)\n",
        "\n",
        "if C.network == 'resnet50':\n",
        "\timport keras_frcnn.resnet as nn\n",
        "elif C.network == 'vgg':\n",
        "\timport keras_frcnn.vgg as nn\n",
        "\n",
        "# turn off any data augmentation at test time\n",
        "C.use_horizontal_flips = False\n",
        "C.use_vertical_flips = False\n",
        "C.rot_90 = False\n",
        "\n",
        "img_path = options.test_path\n",
        "\n",
        "def format_img_size(img, C):\n",
        "\t\"\"\" formats the image size based on config \"\"\"\n",
        "\timg_min_side = float(C.im_size)\n",
        "\t(height,width,_) = img.shape\n",
        "\t\t\n",
        "\tif width <= height:\n",
        "\t\tratio = img_min_side/width\n",
        "\t\tnew_height = int(ratio * height)\n",
        "\t\tnew_width = int(img_min_side)\n",
        "\telse:\n",
        "\t\tratio = img_min_side/height\n",
        "\t\tnew_width = int(ratio * width)\n",
        "\t\tnew_height = int(img_min_side)\n",
        "\timg = cv2.resize(img, (new_width, new_height), interpolation=cv2.INTER_CUBIC)\n",
        "\treturn img, ratio\t\n",
        "\n",
        "def format_img_channels(img, C):\n",
        "\t\"\"\" formats the image channels based on config \"\"\"\n",
        "\timg = img[:, :, (2, 1, 0)]\n",
        "\timg = img.astype(np.float32)\n",
        "\timg[:, :, 0] -= C.img_channel_mean[0]\n",
        "\timg[:, :, 1] -= C.img_channel_mean[1]\n",
        "\timg[:, :, 2] -= C.img_channel_mean[2]\n",
        "\timg /= C.img_scaling_factor\n",
        "\timg = np.transpose(img, (2, 0, 1))\n",
        "\timg = np.expand_dims(img, axis=0)\n",
        "\treturn img\n",
        "\n",
        "def format_img(img, C):\n",
        "\t\"\"\" formats an image for model prediction based on config \"\"\"\n",
        "\timg, ratio = format_img_size(img, C)\n",
        "\timg = format_img_channels(img, C)\n",
        "\treturn img, ratio\n",
        "\n",
        "# Method to transform the coordinates of the bounding box to its original size\n",
        "def get_real_coordinates(ratio, x1, y1, x2, y2):\n",
        "\n",
        "\treal_x1 = int(round(x1 // ratio))\n",
        "\treal_y1 = int(round(y1 // ratio))\n",
        "\treal_x2 = int(round(x2 // ratio))\n",
        "\treal_y2 = int(round(y2 // ratio))\n",
        "\n",
        "\treturn (real_x1, real_y1, real_x2 ,real_y2)\n",
        "\n",
        "class_mapping = C.class_mapping\n",
        "\n",
        "if 'bg' not in class_mapping:\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "class_mapping = {v: k for k, v in class_mapping.items()}\n",
        "print(class_mapping)\n",
        "class_to_color = {class_mapping[v]: np.random.randint(0, 255, 3) for v in class_mapping}\n",
        "C.num_rois = int(options.num_rois)\n",
        "\n",
        "if C.network == 'resnet50':\n",
        "\tnum_features = 1024\n",
        "elif C.network == 'vgg':\n",
        "\tnum_features = 512\n",
        "\n",
        "if K.image_dim_ordering() == 'th':\n",
        "\tinput_shape_img = (3, None, None)\n",
        "\tinput_shape_features = (num_features, None, None)\n",
        "else:\n",
        "\tinput_shape_img = (None, None, 3)\n",
        "\tinput_shape_features = (None, None, num_features)\n",
        "\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(C.num_rois, 4))\n",
        "feature_map_input = Input(shape=input_shape_features)\n",
        "\n",
        "# define the base network (resnet here, can be VGG, Inception, etc)\n",
        "shared_layers = nn.nn_base(img_input, trainable=True)\n",
        "\n",
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn_layers = nn.rpn(shared_layers, num_anchors)\n",
        "\n",
        "classifier = nn.classifier(feature_map_input, roi_input, C.num_rois, nb_classes=len(class_mapping), trainable=True)\n",
        "\n",
        "model_rpn = Model(img_input, rpn_layers)\n",
        "model_classifier_only = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "model_classifier = Model([feature_map_input, roi_input], classifier)\n",
        "\n",
        "print('Loading weights from {}'.format(C.model_path))\n",
        "model_rpn.load_weights(C.model_path, by_name=True)\n",
        "model_classifier.load_weights(C.model_path, by_name=True)\n",
        "\n",
        "model_rpn.compile(optimizer='sgd', loss='mse')\n",
        "model_classifier.compile(optimizer='sgd', loss='mse')\n",
        "\n",
        "all_imgs = []\n",
        "\n",
        "classes = {}\n",
        "\n",
        "bbox_threshold = 0.8\n",
        "\n",
        "visualise = True\n",
        "\n",
        "for idx, img_name in enumerate(sorted(os.listdir(img_path))):\n",
        "\tif not img_name.lower().endswith(('.bmp', '.jpeg', '.jpg', '.png', '.tif', '.tiff')):\n",
        "\t\tcontinue\n",
        "\tprint(img_name)\n",
        "\tst = time.time()\n",
        "\tfilepath = os.path.join(img_path,img_name)\n",
        "\n",
        "\timg = cv2.imread(filepath)\n",
        "\n",
        "\tX, ratio = format_img(img, C)\n",
        "\n",
        "\tif K.image_dim_ordering() == 'tf':\n",
        "\t\tX = np.transpose(X, (0, 2, 3, 1))\n",
        "\n",
        "\t# get the feature maps and output from the RPN\n",
        "\t[Y1, Y2, F] = model_rpn.predict(X)\n",
        "\t\n",
        "\n",
        "\tR = roi_helpers.rpn_to_roi(Y1, Y2, C, K.image_dim_ordering(), overlap_thresh=0.7)\n",
        "\n",
        "\t# convert from (x1,y1,x2,y2) to (x,y,w,h)\n",
        "\tR[:, 2] -= R[:, 0]\n",
        "\tR[:, 3] -= R[:, 1]\n",
        "\n",
        "\t# apply the spatial pyramid pooling to the proposed regions\n",
        "\tbboxes = {}\n",
        "\tprobs = {}\n",
        "\n",
        "\tfor jk in range(R.shape[0]//C.num_rois + 1):\n",
        "\t\tROIs = np.expand_dims(R[C.num_rois*jk:C.num_rois*(jk+1), :], axis=0)\n",
        "\t\tif ROIs.shape[1] == 0:\n",
        "\t\t\tbreak\n",
        "\n",
        "\t\tif jk == R.shape[0]//C.num_rois:\n",
        "\t\t\t#pad R\n",
        "\t\t\tcurr_shape = ROIs.shape\n",
        "\t\t\ttarget_shape = (curr_shape[0],C.num_rois,curr_shape[2])\n",
        "\t\t\tROIs_padded = np.zeros(target_shape).astype(ROIs.dtype)\n",
        "\t\t\tROIs_padded[:, :curr_shape[1], :] = ROIs\n",
        "\t\t\tROIs_padded[0, curr_shape[1]:, :] = ROIs[0, 0, :]\n",
        "\t\t\tROIs = ROIs_padded\n",
        "\n",
        "\t\t[P_cls, P_regr] = model_classifier_only.predict([F, ROIs])\n",
        "\n",
        "\t\tfor ii in range(P_cls.shape[1]):\n",
        "\n",
        "\t\t\tif np.max(P_cls[0, ii, :]) < bbox_threshold or np.argmax(P_cls[0, ii, :]) == (P_cls.shape[2] - 1):\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tcls_name = class_mapping[np.argmax(P_cls[0, ii, :])]\n",
        "\n",
        "\t\t\tif cls_name not in bboxes:\n",
        "\t\t\t\tbboxes[cls_name] = []\n",
        "\t\t\t\tprobs[cls_name] = []\n",
        "\n",
        "\t\t\t(x, y, w, h) = ROIs[0, ii, :]\n",
        "\n",
        "\t\t\tcls_num = np.argmax(P_cls[0, ii, :])\n",
        "\t\t\ttry:\n",
        "\t\t\t\t(tx, ty, tw, th) = P_regr[0, ii, 4*cls_num:4*(cls_num+1)]\n",
        "\t\t\t\ttx /= C.classifier_regr_std[0]\n",
        "\t\t\t\tty /= C.classifier_regr_std[1]\n",
        "\t\t\t\ttw /= C.classifier_regr_std[2]\n",
        "\t\t\t\tth /= C.classifier_regr_std[3]\n",
        "\t\t\t\tx, y, w, h = roi_helpers.apply_regr(x, y, w, h, tx, ty, tw, th)\n",
        "\t\t\texcept:\n",
        "\t\t\t\tpass\n",
        "\t\t\tbboxes[cls_name].append([C.rpn_stride*x, C.rpn_stride*y, C.rpn_stride*(x+w), C.rpn_stride*(y+h)])\n",
        "\t\t\tprobs[cls_name].append(np.max(P_cls[0, ii, :]))\n",
        "\n",
        "\tall_dets = []\n",
        "\n",
        "\tfor key in bboxes:\n",
        "\t\tbbox = np.array(bboxes[key])\n",
        "\n",
        "\t\tnew_boxes, new_probs = roi_helpers.non_max_suppression_fast(bbox, np.array(probs[key]), overlap_thresh=0.5)\n",
        "\t\tfor jk in range(new_boxes.shape[0]):\n",
        "\t\t\t(x1, y1, x2, y2) = new_boxes[jk,:]\n",
        "\n",
        "\t\t\t(real_x1, real_y1, real_x2, real_y2) = get_real_coordinates(ratio, x1, y1, x2, y2)\n",
        "\n",
        "\t\t\tcv2.rectangle(img,(real_x1, real_y1), (real_x2, real_y2), (int(class_to_color[key][0]), int(class_to_color[key][1]), int(class_to_color[key][2])),2)\n",
        "\n",
        "\t\t\ttextLabel = '{}: {}'.format(key,int(100*new_probs[jk]))\n",
        "\t\t\tall_dets.append((key,100*new_probs[jk]))\n",
        "\n",
        "\t\t\t(retval,baseLine) = cv2.getTextSize(textLabel,cv2.FONT_HERSHEY_COMPLEX,1,1)\n",
        "\t\t\ttextOrg = (real_x1, real_y1-0)\n",
        "\n",
        "\t\t\tcv2.rectangle(img, (textOrg[0] - 5, textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (0, 0, 0), 2)\n",
        "\t\t\tcv2.rectangle(img, (textOrg[0] - 5,textOrg[1]+baseLine - 5), (textOrg[0]+retval[0] + 5, textOrg[1]-retval[1] - 5), (255, 255, 255), -1)\n",
        "\t\t\tcv2.putText(img, textLabel, textOrg, cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 0), 1)\n",
        "\n",
        "\tprint('Elapsed time = {}'.format(time.time() - st))\n",
        "\tprint(all_dets)\n",
        "\tcv2.imshow('img', img)\n",
        "\tcv2.waitKey(0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "DopUkxCyfxy3",
        "outputId": "5eb90088-ffa8-4b21-e7e0-e1f8172618d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-0ba9ef1b73e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0moptparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptionParser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_frcnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras_frcnn'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import random\n",
        "import pprint\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "from optparse import OptionParser\n",
        "import pickle\n",
        "from keras import backend as K\n",
        "from keras.optimizers import Adam, SGD, RMSprop\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.utils import generic_utils\n",
        "\n",
        "sys.setrecursionlimit(40000)\n",
        "\n",
        "parser = OptionParser()\n",
        "\n",
        "parser.add_option(\"-p\", \"--path\", dest=\"train_path\", help=\"Path to training data.\")\n",
        "parser.add_option(\"-o\", \"--parser\", dest=\"parser\", help=\"Parser to use. One of simple or pascal_voc\",\n",
        "\t\t\t\tdefault=\"pascal_voc\")\n",
        "parser.add_option(\"-n\", \"--num_rois\", type=\"int\", dest=\"num_rois\", help=\"Number of RoIs to process at once.\", default=32)\n",
        "parser.add_option(\"--network\", dest=\"network\", help=\"Base network to use. Supports vgg or resnet50.\", default='resnet50')\n",
        "parser.add_option(\"--hf\", dest=\"horizontal_flips\", help=\"Augment with horizontal flips in training. (Default=false).\", action=\"store_true\", default=False)\n",
        "parser.add_option(\"--vf\", dest=\"vertical_flips\", help=\"Augment with vertical flips in training. (Default=false).\", action=\"store_true\", default=False)\n",
        "parser.add_option(\"--rot\", \"--rot_90\", dest=\"rot_90\", help=\"Augment with 90 degree rotations in training. (Default=false).\",\n",
        "\t\t\t\t  action=\"store_true\", default=False)\n",
        "parser.add_option(\"--num_epochs\", type=\"int\", dest=\"num_epochs\", help=\"Number of epochs.\", default=100)\n",
        "parser.add_option(\"--config_filename\", dest=\"config_filename\", help=\n",
        "\t\t\t\t\"Location to store all the metadata related to the training (to be used when testing).\",\n",
        "\t\t\t\tdefault=\"config.pickle\")\n",
        "parser.add_option(\"--output_weight_path\", dest=\"output_weight_path\", help=\"Output path for weights.\", default='./model_frcnn.hdf5')\n",
        "parser.add_option(\"--input_weight_path\", dest=\"input_weight_path\", help=\"Input path for weights. If not specified, will try to load default weights provided by keras.\")\n",
        "\n",
        "(options, args) = parser.parse_args()\n",
        "\n",
        "if not options.train_path:   # if filename is not given\n",
        "\tparser.error('Error: path to training data must be specified. Pass --path to command line')\n",
        "\n",
        "if options.parser == 'pascal_voc':\n",
        "\tfrom . import get_data\n",
        "elif options.parser == 'simple':\n",
        "\tfrom . import get_data\n",
        "else:\n",
        "\traise ValueError(\"Command line option parser must be one of 'pascal_voc' or 'simple'\")\n",
        "\n",
        "# pass the settings from the command line, and persist them in the config object\n",
        "C = config.Config()\n",
        "\n",
        "C.use_horizontal_flips = bool(options.horizontal_flips)\n",
        "C.use_vertical_flips = bool(options.vertical_flips)\n",
        "C.rot_90 = bool(options.rot_90)\n",
        "\n",
        "C.model_path = options.output_weight_path\n",
        "C.num_rois = int(options.num_rois)\n",
        "\n",
        "if options.network == 'vgg':\n",
        "\tC.network = 'vgg'\n",
        "\tfrom . import vgg as nn\n",
        "elif options.network == 'resnet50':\n",
        "\tfrom . import resnet as nn\n",
        "\tC.network = 'resnet50'\n",
        "else:\n",
        "\tprint('Not a valid model')\n",
        "\traise ValueError\n",
        "\n",
        "\n",
        "# check if weight path was passed via command line\n",
        "if options.input_weight_path:\n",
        "\tC.base_net_weights = options.input_weight_path\n",
        "else:\n",
        "\t# set the path to weights based on backend and model\n",
        "\tC.base_net_weights = nn.get_weight_path()\n",
        "\n",
        "all_imgs, classes_count, class_mapping = get_data(options.train_path)\n",
        "\n",
        "if 'bg' not in classes_count:\n",
        "\tclasses_count['bg'] = 0\n",
        "\tclass_mapping['bg'] = len(class_mapping)\n",
        "\n",
        "C.class_mapping = class_mapping\n",
        "\n",
        "inv_map = {v: k for k, v in class_mapping.items()}\n",
        "\n",
        "print('Training images per class:')\n",
        "pprint.pprint(classes_count)\n",
        "print('Num classes (including bg) = {}'.format(len(classes_count)))\n",
        "\n",
        "config_output_filename = options.config_filename\n",
        "\n",
        "with open(config_output_filename, 'wb') as config_f:\n",
        "\tpickle.dump(C,config_f)\n",
        "\tprint('Config has been written to {}, and can be loaded when testing to ensure correct results'.format(config_output_filename))\n",
        "\n",
        "random.shuffle(all_imgs)\n",
        "\n",
        "num_imgs = len(all_imgs)\n",
        "\n",
        "train_imgs = [s for s in all_imgs if s['imageset'] == 'trainval']\n",
        "val_imgs = [s for s in all_imgs if s['imageset'] == 'test']\n",
        "\n",
        "print('Num train samples {}'.format(len(train_imgs)))\n",
        "print('Num val samples {}'.format(len(val_imgs)))\n",
        "\n",
        "\n",
        "data_gen_train = data_generators.get_anchor_gt(train_imgs, classes_count, C, nn.get_img_output_length, K.image_dim_ordering(), mode='train')\n",
        "data_gen_val = data_generators.get_anchor_gt(val_imgs, classes_count, C, nn.get_img_output_length,K.image_dim_ordering(), mode='val')\n",
        "\n",
        "if K.image_dim_ordering() == 'th':\n",
        "\tinput_shape_img = (3, None, None)\n",
        "else:\n",
        "\tinput_shape_img = (None, None, 3)\n",
        "\n",
        "img_input = Input(shape=input_shape_img)\n",
        "roi_input = Input(shape=(None, 4))\n",
        "\n",
        "# define the base network (resnet here, can be VGG, Inception, etc)\n",
        "shared_layers = nn.nn_base(img_input, trainable=True)\n",
        "\n",
        "# define the RPN, built on the base layers\n",
        "num_anchors = len(C.anchor_box_scales) * len(C.anchor_box_ratios)\n",
        "rpn = nn.rpn(shared_layers, num_anchors)\n",
        "\n",
        "classifier = nn.classifier(shared_layers, roi_input, C.num_rois, nb_classes=len(classes_count), trainable=True)\n",
        "\n",
        "model_rpn = Model(img_input, rpn[:2])\n",
        "model_classifier = Model([img_input, roi_input], classifier)\n",
        "\n",
        "# this is a model that holds both the RPN and the classifier, used to load/save weights for the models\n",
        "model_all = Model([img_input, roi_input], rpn[:2] + classifier)\n",
        "\n",
        "try:\n",
        "\tprint('loading weights from {}'.format(C.base_net_weights))\n",
        "\tmodel_rpn.load_weights(C.base_net_weights, by_name=True)\n",
        "\tmodel_classifier.load_weights(C.base_net_weights, by_name=True)\n",
        "except:\n",
        "\tprint('Could not load pretrained model weights. Weights can be found in the keras application folder \\\n",
        "\t\thttps://github.com/fchollet/keras/tree/master/keras/applications')\n",
        "\n",
        "optimizer = Adam(lr=1e-5)\n",
        "optimizer_classifier = Adam(lr=1e-5)\n",
        "model_rpn.compile(optimizer=optimizer, loss=[losses.rpn_loss_cls(num_anchors), losses.rpn_loss_regr(num_anchors)])\n",
        "model_classifier.compile(optimizer=optimizer_classifier, loss=[losses.class_loss_cls, losses.class_loss_regr(len(classes_count)-1)], metrics={'dense_class_{}'.format(len(classes_count)): 'accuracy'})\n",
        "model_all.compile(optimizer='sgd', loss='mae')\n",
        "\n",
        "epoch_length = 1000\n",
        "num_epochs = int(options.num_epochs)\n",
        "iter_num = 0\n",
        "\n",
        "losses = np.zeros((epoch_length, 5))\n",
        "rpn_accuracy_rpn_monitor = []\n",
        "rpn_accuracy_for_epoch = []\n",
        "start_time = time.time()\n",
        "\n",
        "best_loss = np.Inf\n",
        "\n",
        "class_mapping_inv = {v: k for k, v in class_mapping.items()}\n",
        "print('Starting training')\n",
        "\n",
        "vis = True\n",
        "\n",
        "for epoch_num in range(num_epochs):\n",
        "\n",
        "\tprogbar = generic_utils.Progbar(epoch_length)\n",
        "\tprint('Epoch {}/{}'.format(epoch_num + 1, num_epochs))\n",
        "\n",
        "\twhile True:\n",
        "\t\ttry:\n",
        "\n",
        "\t\t\tif len(rpn_accuracy_rpn_monitor) == epoch_length and C.verbose:\n",
        "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_rpn_monitor))/len(rpn_accuracy_rpn_monitor)\n",
        "\t\t\t\trpn_accuracy_rpn_monitor = []\n",
        "\t\t\t\tprint('Average number of overlapping bounding boxes from RPN = {} for {} previous iterations'.format(mean_overlapping_bboxes, epoch_length))\n",
        "\t\t\t\tif mean_overlapping_bboxes == 0:\n",
        "\t\t\t\t\tprint('RPN is not producing bounding boxes that overlap the ground truth boxes. Check RPN settings or keep training.')\n",
        "\n",
        "\t\t\tX, Y, img_data = next(data_gen_train)\n",
        "\n",
        "\t\t\tloss_rpn = model_rpn.train_on_batch(X, Y)\n",
        "\n",
        "\t\t\tP_rpn = model_rpn.predict_on_batch(X)\n",
        "\n",
        "\t\t\tR = roi_helpers.rpn_to_roi(P_rpn[0], P_rpn[1], C, K.image_dim_ordering(), use_regr=True, overlap_thresh=0.7, max_boxes=300)\n",
        "\t\t\t# note: calc_iou converts from (x1,y1,x2,y2) to (x,y,w,h) format\n",
        "\t\t\tX2, Y1, Y2, IouS = roi_helpers.calc_iou(R, img_data, C, class_mapping)\n",
        "\n",
        "\t\t\tif X2 is None:\n",
        "\t\t\t\trpn_accuracy_rpn_monitor.append(0)\n",
        "\t\t\t\trpn_accuracy_for_epoch.append(0)\n",
        "\t\t\t\tcontinue\n",
        "\n",
        "\t\t\tneg_samples = np.where(Y1[0, :, -1] == 1)\n",
        "\t\t\tpos_samples = np.where(Y1[0, :, -1] == 0)\n",
        "\n",
        "\t\t\tif len(neg_samples) > 0:\n",
        "\t\t\t\tneg_samples = neg_samples[0]\n",
        "\t\t\telse:\n",
        "\t\t\t\tneg_samples = []\n",
        "\n",
        "\t\t\tif len(pos_samples) > 0:\n",
        "\t\t\t\tpos_samples = pos_samples[0]\n",
        "\t\t\telse:\n",
        "\t\t\t\tpos_samples = []\n",
        "\t\t\t\n",
        "\t\t\trpn_accuracy_rpn_monitor.append(len(pos_samples))\n",
        "\t\t\trpn_accuracy_for_epoch.append((len(pos_samples)))\n",
        "\n",
        "\t\t\tif C.num_rois > 1:\n",
        "\t\t\t\tif len(pos_samples) < C.num_rois//2:\n",
        "\t\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tselected_pos_samples = np.random.choice(pos_samples, C.num_rois//2, replace=False).tolist()\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=False).tolist()\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tselected_neg_samples = np.random.choice(neg_samples, C.num_rois - len(selected_pos_samples), replace=True).tolist()\n",
        "\n",
        "\t\t\t\tsel_samples = selected_pos_samples + selected_neg_samples\n",
        "\t\t\telse:\n",
        "\t\t\t\t# in the extreme case where num_rois = 1, we pick a random pos or neg sample\n",
        "\t\t\t\tselected_pos_samples = pos_samples.tolist()\n",
        "\t\t\t\tselected_neg_samples = neg_samples.tolist()\n",
        "\t\t\t\tif np.random.randint(0, 2):\n",
        "\t\t\t\t\tsel_samples = random.choice(neg_samples)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tsel_samples = random.choice(pos_samples)\n",
        "\n",
        "\t\t\tloss_class = model_classifier.train_on_batch([X, X2[:, sel_samples, :]], [Y1[:, sel_samples, :], Y2[:, sel_samples, :]])\n",
        "\n",
        "\t\t\tlosses[iter_num, 0] = loss_rpn[1]\n",
        "\t\t\tlosses[iter_num, 1] = loss_rpn[2]\n",
        "\n",
        "\t\t\tlosses[iter_num, 2] = loss_class[1]\n",
        "\t\t\tlosses[iter_num, 3] = loss_class[2]\n",
        "\t\t\tlosses[iter_num, 4] = loss_class[3]\n",
        "\n",
        "\t\t\tprogbar.update(iter_num+1, [('rpn_cls', losses[iter_num, 0]), ('rpn_regr', losses[iter_num, 1]),\n",
        "\t\t\t\t\t\t\t\t\t  ('detector_cls', losses[iter_num, 2]), ('detector_regr', losses[iter_num, 3])])\n",
        "\n",
        "\t\t\titer_num += 1\n",
        "\t\t\t\n",
        "\t\t\tif iter_num == epoch_length:\n",
        "\t\t\t\tloss_rpn_cls = np.mean(losses[:, 0])\n",
        "\t\t\t\tloss_rpn_regr = np.mean(losses[:, 1])\n",
        "\t\t\t\tloss_class_cls = np.mean(losses[:, 2])\n",
        "\t\t\t\tloss_class_regr = np.mean(losses[:, 3])\n",
        "\t\t\t\tclass_acc = np.mean(losses[:, 4])\n",
        "\n",
        "\t\t\t\tmean_overlapping_bboxes = float(sum(rpn_accuracy_for_epoch)) / len(rpn_accuracy_for_epoch)\n",
        "\t\t\t\trpn_accuracy_for_epoch = []\n",
        "\n",
        "\t\t\t\tif C.verbose:\n",
        "\t\t\t\t\tprint('Mean number of bounding boxes from RPN overlapping ground truth boxes: {}'.format(mean_overlapping_bboxes))\n",
        "\t\t\t\t\tprint('Classifier accuracy for bounding boxes from RPN: {}'.format(class_acc))\n",
        "\t\t\t\t\tprint('Loss RPN classifier: {}'.format(loss_rpn_cls))\n",
        "\t\t\t\t\tprint('Loss RPN regression: {}'.format(loss_rpn_regr))\n",
        "\t\t\t\t\tprint('Loss Detector classifier: {}'.format(loss_class_cls))\n",
        "\t\t\t\t\tprint('Loss Detector regression: {}'.format(loss_class_regr))\n",
        "\t\t\t\t\tprint('Elapsed time: {}'.format(time.time() - start_time))\n",
        "\n",
        "\t\t\t\tcurr_loss = loss_rpn_cls + loss_rpn_regr + loss_class_cls + loss_class_regr\n",
        "\t\t\t\titer_num = 0\n",
        "\t\t\t\tstart_time = time.time()\n",
        "\n",
        "\t\t\t\tif curr_loss < best_loss:\n",
        "\t\t\t\t\tif C.verbose:\n",
        "\t\t\t\t\t\tprint('Total loss decreased from {} to {}, saving weights'.format(best_loss,curr_loss))\n",
        "\t\t\t\t\tbest_loss = curr_loss\n",
        "\t\t\t\t\tmodel_all.save_weights(C.model_path)\n",
        "\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\texcept Exception as e:\n",
        "\t\t\tprint('Exception: {}'.format(e))\n",
        "\t\t\tcontinue\n",
        "\n",
        "print('Training complete, exiting.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "id": "3tBwuRbaf1K9",
        "outputId": "cb2cf170-3af5-4f50-a164-10437ed40de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Usage:  [options]\n",
            "\n",
            ": error: Error: path to training data must be specified. Pass --path to command line\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    }
  ]
}